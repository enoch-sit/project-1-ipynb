{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFTMiM0TN_1Y"
      },
      "source": [
        "# Function Calling with Grok API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR0lk5cWN_1Z"
      },
      "source": [
        "## Step 1: Install Required Packages\n",
        "\n",
        "Run this cell to install LangChain, the OpenAI integration (which works with Grok's compatible API), and Requests (for API calls)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRUqQ05PN_1Z",
        "outputId": "a464ad31-935f-431c-8ea9-d243e29549d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain_openai requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn28xteIN_1Z"
      },
      "source": [
        "## Step 2: Import Libraries and Set Up Your API Key\n",
        "\n",
        "We'll import the necessary modules and set up the Grok model via its API. Replace `'your-api-key-here'` with your actual xAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z7e2J5sHN_1Z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"XAI_API_KEY\"] = userdata.get('grokapi')\n",
        "\n",
        "# Set up the Grok model using ChatOpenAI (Grok API is OpenAI-compatible)\n",
        "llm = ChatOpenAI(\n",
        "    base_url=\"https://api.x.ai/v1\",\n",
        "    api_key=os.environ[\"XAI_API_KEY\"],\n",
        "    model=\"grok-3-mini\",  # Use the appropriate Grok model name (check https://docs.x.ai for latest)\n",
        "    temperature=0,  # Low temperature for consistent tool calling\n",
        "    streaming=False,  # Non-streaming for simplicity\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dnXc4BAN_1Z"
      },
      "source": [
        "**Quick Explanation:**\n",
        "- `ChatOpenAI` is used with a custom `base_url` to point to xAI's API endpoint.\n",
        "- Grok's API is compatible with OpenAI's format, so this works seamlessly.\n",
        "- `temperature=0` makes the model more deterministic (good for beginners).\n",
        "- We're using non-streaming mode to get full responses at once. Note: Grok streams function calls in a single chunk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roheiVrGN_1a"
      },
      "source": [
        "## Step 3: Understand Function Calling\n",
        "\n",
        "**What is Function Calling?**\n",
        "- LLMs like Grok can't access the internet or real-time data directly.\n",
        "- Function Calling lets the LLM \"call\" a predefined function (tool) with parameters.\n",
        "- Example: User asks \"What's the weather in Hong Kong?\" ‚Üí Grok calls a `get_current_weather` tool ‚Üí Tool fetches data from an API ‚Üí Grok summarizes it.\n",
        "\n",
        "In LangChain with Grok API:\n",
        "- Define tools with the `@tool` decorator (includes name, description, and parameters).\n",
        "- \"Bind\" the tool to the LLM so it knows when/how to use it.\n",
        "- Invoke the LLM with a user query, and it handles the rest!\n",
        "\n",
        "Our tool will use the **Hong Kong Observatory (HKO) Open Data Weather API** to get real-time weather (e.g., temperature, humidity).\n",
        "\n",
        "**Grok-Specific Notes:**\n",
        "- Grok supports parallel function calling by default (multiple tools in one response).\n",
        "- Use `tool_choice` to control behavior: 'auto' (default), 'required', specific function, or 'none' to disable.\n",
        "- Tools are defined in the request body and can be referenced by ID in responses.\n",
        "\n",
        "### Grok Function Calling Flow\n",
        "Here's a diagram of the function calling process:\n",
        "![Function Call Flow](https://docs.x.ai/assets/docs/guides/function-calling/function-call.png)\n",
        "\n",
        "### Example Local Server Setup\n",
        "If you're setting up a local server for testing:\n",
        "![Local Server](https://docs.x.ai/assets/docs/guides/function-calling/local-server.png)\n",
        "\n",
        "### New Request Body Example\n",
        "An example of the request body when calling the API:\n",
        "![New Request Body](https://docs.x.ai/assets/docs/guides/function-calling/new-request-body.png)\n",
        "\n",
        "### Responding Request Body Example\n",
        "An example of how to respond with tool results:\n",
        "![Responding Request Body](https://docs.x.ai/assets/docs/guides/function-calling/responding-request-body.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JceDN-BN_1a"
      },
      "source": [
        "## Step 4: Define the \"Get Current Weather\" Tool\n",
        "\n",
        "We'll create a tool that calls the HKO API for current weather reports (`dataType=rhrread`). It's Hong Kong-specific, so no location parameter needed for simplicity.\n",
        "\n",
        "The tool fetches JSON data and returns a formatted string.\n",
        "\n",
        "**Explaining Pydantic and Raw Dictionary Definitions:**\n",
        "\n",
        "- **Pydantic**: This is a Python library for data validation and settings management using type hints. In LangChain, when you use `@tool` with type-annotated arguments (e.g., `place: str`), it automatically generates a JSON schema for the tool using Pydantic models under the hood. This reduces errors by enforcing structure and types (e.g., ensuring 'place' is a string). It's great for complex tools with multiple params.\n",
        "\n",
        "- **Raw Dictionary**: If you don't want to use Pydantic, you can define tools as plain Python dictionaries with a JSON schema. This is more manual but flexible‚Äîno dependencies on Pydantic. Example schema: `{'type': 'function', 'function': {'name': 'get_current_weather', 'description': 'Get weather...', 'parameters': {'type': 'object', 'properties': {'place': {'type': 'string'}}, 'required': ['place']}}}`. Pass a list of such dicts to `llm.bind_tools([tool_dict])`.\n",
        "\n",
        "We'll use the Pydantic way (@tool) for simplicity, but I'll show the raw dict equivalent below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bL2DJ_qTN_1a"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_current_weather(place: str) -> str:\n",
        "    \"\"\"\n",
        "    Get the current weather in a given place (e.g., 'Hong Kong').\n",
        "\n",
        "    This tool uses the Hong Kong Observatory API to fetch real-time data like temperature and humidity.\n",
        "    For now, it only works for places in Hong Kong.\n",
        "\n",
        "    Args:\n",
        "        place (str): The place name (e.g., \"Hong Kong\").\n",
        "\n",
        "    Returns:\n",
        "        str: A summary of the current weather.\n",
        "    \"\"\"\n",
        "    if \"hong kong\" not in place.lower():\n",
        "        return \"Sorry, this tool only supports weather for Hong Kong locations.\"\n",
        "\n",
        "    # HKO API endpoint for current weather report\n",
        "    url = \"https://data.weather.gov.hk/weatherAPI/opendata/weather.php\"\n",
        "    params = {\n",
        "        \"dataType\": \"rhrread\",\n",
        "        \"lang\": \"en\"  # English\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params, timeout=10)\n",
        "        response.raise_for_status()  # Raise error for bad status\n",
        "        data = response.json()\n",
        "\n",
        "        # Extract key info (corrected paths based on actual API structure)\n",
        "        update_time = data.get(\"updateTime\", \"Unknown\")\n",
        "        temperature_data = data.get(\"temperature\", {}).get(\"data\", [])\n",
        "        humidity_data = data.get(\"humidity\", {}).get(\"data\", [])\n",
        "        warnings = data.get(\"warningMessage\", []) or data.get(\"specialWxTips\", [])\n",
        "\n",
        "        # Get first station's temp and humidity (e.g., King's Park or HKO)\n",
        "        temp = temperature_data[0][\"value\"] if temperature_data else \"N/A\"\n",
        "        hum = humidity_data[0][\"value\"] if humidity_data else \"N/A\"\n",
        "\n",
        "        summary = f\"Current weather in Hong Kong (reported at {update_time}):\\n\"\n",
        "        summary += f\"- Temperature: {temp}¬∞C\\n\"\n",
        "        summary += f\"- Humidity: {hum}%\\n\"\n",
        "\n",
        "        if warnings:\n",
        "            summary += f\"- Warnings/Tips: {'; '.join(warnings)}\\n\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching weather: {str(e)}\"\n",
        "\n",
        "# Alternative: Raw Dictionary Definition (no @tool or Pydantic)\n",
        "get_current_weather_dict = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather in a given place (e.g., 'Hong Kong'). This tool uses the Hong Kong Observatory API.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"place\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The place name (e.g., \\\"Hong Kong\\\").\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"place\"]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFeQ6cddN_1a"
      },
      "source": [
        "**Quick Explanation:**\n",
        "- `@tool` turns the function into a LangChain tool using Pydantic for schema. The docstring describes it for the LLM.\n",
        "- For raw dict: Use this if avoiding Pydantic; it's a JSON schema that LangChain can bind directly.\n",
        "- We use `requests.get` to call the HKO API (base URL from docs).\n",
        "- Parse the JSON response (structure from HKO docs: nested `data` with `temperature`, `humidity`, etc.).\n",
        "- Return a human-readable string. In a real app, you'd handle more fields!\n",
        "\n",
        "Test the tool standalone:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdoMUBYsN_1a",
        "outputId": "a30aaef7-f8a9-4d34-9218-3ca7802c84c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current weather in Hong Kong (reported at 2025-09-23T09:02:00+08:00):\n",
            "- Temperature: 29¬∞C\n",
            "- Humidity: 69%\n",
            "- Warnings/Tips: The Tropical Cyclone Signal No. 3 has been issued.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Quick test of the tool\n",
        "print(get_current_weather.invoke({\"place\": \"Hong Kong\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHFHIaUhN_1a"
      },
      "source": [
        "## Step 5: Bind the Tool to the LLM\n",
        "\n",
        "Now, \"bind\" the tool to our LLM. This tells the model it can use `get_current_weather` when needed. We'll use the Pydantic version, but you could bind the dict instead: `llm.bind_tools([get_current_weather_dict])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20HPlDiKN_1a",
        "outputId": "c9c39cc2-a6b3-4320-e7b4-1441b4898754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langchain_core.utils.pydantic.get_current_weather'>\n"
          ]
        }
      ],
      "source": [
        "# Bind the tool to the LLM (Pydantic version)\n",
        "llm_with_tools = llm.bind_tools([get_current_weather])\n",
        "\n",
        "# Alternative: Bind raw dict\n",
        "# llm_with_tools = llm.bind_tools([get_current_weather_dict])\n",
        "\n",
        "# Print the tool schema directly (what the LLM sees)\n",
        "print(get_current_weather.get_input_schema())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uvz0i64N_1a"
      },
      "source": [
        "**What happens under the hood?**\n",
        "- The LLM gets the tool's schema (name, description, parameters).\n",
        "- When you query, the LLM decides: \"Do I need this tool?\" If yes, it outputs a \"tool call\" with args.\n",
        "- LangChain executes the tool and feeds the result back to the LLM for a final response.\n",
        "\n",
        "**Grok-Specific:** Parallel calls are enabled by default; set `parallel_function_calling: \"false\"` in API params if needed (via extra kwargs in LangChain)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEU5fJd0N_1a"
      },
      "source": [
        "## Step 6: Create a Simple Chain and Run Examples\n",
        "\n",
        "We'll use a fixed step-by-step approach with JSON forcing for tool decisions, adapted from the original. This ensures clean handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4waYj_M9XbET",
        "outputId": "b51a9f1e-6675-4604-d025-fc999997b857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw JSON Output: {\n",
            "  \"use_tool\": true,\n",
            "  \"tool_name\": \"get_current_weather\",\n",
            "  \"args\": {\n",
            "    \"place\": \"Hong Kong\"\n",
            "  }\n",
            "}\n",
            "Tool Executed! Result: Current weather in Hong Kong (reported at 2025-09-23T09:02:00+08:00):\n",
            "- Temperature: 29¬∞C\n",
            "- Humidity: 69%\n",
            "- Warnings/Tips: The Tropical Cyclone Signal No. 3 has been issued.\n",
            "\n",
            "Final Summary: Hey there! The current weather in Hong Kong is quite warm at 29¬∞C with 69% humidity, making it feel a bit sticky. Just a heads up, Tropical Cyclone Signal No. 3 is in effect, so stay safe and keep an eye on updates. If you're heading out, consider securing loose items and avoiding unnecessary travel! üòä\n"
          ]
        }
      ],
      "source": [
        "# Fixed Step-by-Step Forcing: JSON-Only Tool Decision + Clean Summary\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "import json\n",
        "\n",
        "def force_tool_via_json(user_input: str):\n",
        "    # Phase 1: Prompt for JSON-only tool decision (strict format)\n",
        "    json_prompt = SystemMessage(content=\"\"\"You are a tool-calling assistant. Analyze the user query and respond\n",
        "    **ONLY** with valid JSON in this exact format:\n",
        "    {\n",
        "      \"use_tool\": true/false,  // true if query is about CURRENT weather in Hong Kong\n",
        "      \"tool_name\": \"get_current_weather\" or null,\n",
        "      \"args\": {\"place\": \"string\"} or null  // e.g., {\"place\": \"Hong Kong\"}\n",
        "    }\n",
        "    Do NOT output any other text, explanations, or markdown. If not current weather, set use_tool=false.\"\"\")\n",
        "\n",
        "    messages = [json_prompt, HumanMessage(content=user_input)]\n",
        "\n",
        "    try:\n",
        "        json_response = llm_with_tools.invoke(messages)  # Use bound LLM for schema awareness\n",
        "        json_str = json_response.content.strip()  # Extract content\n",
        "        print(\"Raw JSON Output:\", json_str)  # Debug: See what it outputs\n",
        "\n",
        "        # Phase 2: Parse and execute\n",
        "        tool_plan = json.loads(json_str)\n",
        "        if tool_plan.get(\"use_tool\") and tool_plan.get(\"tool_name\") == \"get_current_weather\":\n",
        "            args = tool_plan.get(\"args\", {})\n",
        "            tool_result = get_current_weather.invoke(args)\n",
        "            print(\"Tool Executed! Result:\", tool_result)\n",
        "\n",
        "            # Phase 3: NEW fresh messages for summarization (no JSON prompt!)\n",
        "            summary_system = SystemMessage(content=\"\"\"You are a helpful weather assistant.\n",
        "            Summarize the provided tool result in a natural, friendly response to the user's query.\n",
        "            Include key details like temperature, humidity, and warnings. Keep it concise and engaging.\"\"\")\n",
        "\n",
        "            # Fresh chain: User query + tool result only\n",
        "            summary_messages = [\n",
        "                summary_system,\n",
        "                HumanMessage(content=user_input),\n",
        "                HumanMessage(content=f\"Tool result: {tool_result}\")\n",
        "            ]\n",
        "            final_response = llm.invoke(summary_messages)  # Use unbound LLM for free-form text\n",
        "            return final_response.content\n",
        "        else:\n",
        "            return \"No tool needed for this query.\"\n",
        "    except json.JSONDecodeError:\n",
        "        return \"Error: LLM didn't output valid JSON. Try rephrasing.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Test it\n",
        "user_query = \"What's the current weather in Hong Kong?\"\n",
        "result = force_tool_via_json(user_query)\n",
        "print(\"Final Summary:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sltOecJSN_1b"
      },
      "source": [
        "## Step 7: What's Next?\n",
        "\n",
        "Congrats! You've built your first Function Calling app with Grok API. Experiment with more tools or modes like `tool_choice='required'`.\n",
        "\n",
        "**Resources:**\n",
        "- [xAI Grok API Docs: Function Calling](https://docs.x.ai/docs/guides/function-calling)\n",
        "- [LangChain Docs: Tools](https://python.langchain.com/docs/modules/agents/tools/)\n",
        "- [HKO API Full Docs](https://www.hko.gov.hk/en/weatherAPI/doc/files/HKO_Open_Data_API_Documentation.pdf)\n",
        "- Questions? Ask in the comments!\n",
        "\n",
        "Happy coding! üå§Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sdk_install"
      },
      "outputs": [],
      "source": [
        "!pip install -q xai-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HkCuYhyFP_d4",
        "outputId": "4bd02d79-b753-4cf6-84c9-9284232e3ae9"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"mermaid-1758592349615\" width=\"100%\" style=\"max-width: 1020px;\" viewBox=\"-50 -10 1020 1450\" role=\"graphics-document document\" aria-roledescription=\"sequence\"><g><rect x=\"770\" y=\"1364\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Tools\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"845\" y=\"1396.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"845\" dy=\"0\">Tool Functions</tspan></text></g><g><rect x=\"570\" y=\"1364\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Grok\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"645\" y=\"1396.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"645\" dy=\"0\">Grok API</tspan></text></g><g><rect x=\"262\" y=\"1364\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Client\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"337\" y=\"1396.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"337\" dy=\"0\">Client Application</tspan></text></g><g><rect x=\"0\" y=\"1364\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"User\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"75\" y=\"1396.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">User</tspan></text></g><g><line id=\"actor3\" x1=\"845\" y1=\"65\" x2=\"845\" y2=\"1364\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"Tools\"/><g id=\"root-3\"><rect x=\"770\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Tools\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"845\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"845\" dy=\"0\">Tool Functions</tspan></text></g></g><g><line id=\"actor2\" x1=\"645\" y1=\"65\" x2=\"645\" y2=\"1364\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"Grok\"/><g id=\"root-2\"><rect x=\"570\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Grok\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"645\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"645\" dy=\"0\">Grok API</tspan></text></g></g><g><line id=\"actor1\" x1=\"337\" y1=\"65\" x2=\"337\" y2=\"1364\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"Client\"/><g id=\"root-1\"><rect x=\"262\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"Client\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"337\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"337\" dy=\"0\">Client Application</tspan></text></g></g><g><line id=\"actor0\" x1=\"75\" y1=\"65\" x2=\"75\" y2=\"1364\" class=\"actor-line 200\" stroke-width=\"0.5px\" stroke=\"#999\" name=\"User\"/><g id=\"root-0\"><rect x=\"0\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"User\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"75\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor actor-box\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">User</tspan></text></g></g><style>#mermaid-1758592349615{font-family:&quot;trebuchet ms&quot;,verdana,arial,sans-serif;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-1758592349615 .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-1758592349615 .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-1758592349615 .error-icon{fill:#552222;}#mermaid-1758592349615 .error-text{fill:#552222;stroke:#552222;}#mermaid-1758592349615 .edge-thickness-normal{stroke-width:1px;}#mermaid-1758592349615 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-1758592349615 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-1758592349615 .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-1758592349615 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-1758592349615 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-1758592349615 .marker{fill:#333333;stroke:#333333;}#mermaid-1758592349615 .marker.cross{stroke:#333333;}#mermaid-1758592349615 svg{font-family:&quot;trebuchet ms&quot;,verdana,arial,sans-serif;font-size:16px;}#mermaid-1758592349615 p{margin:0;}#mermaid-1758592349615 .actor{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-1758592349615 text.actor&gt;tspan{fill:black;stroke:none;}#mermaid-1758592349615 .actor-line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#mermaid-1758592349615 .innerArc{stroke-width:1.5;stroke-dasharray:none;}#mermaid-1758592349615 .messageLine0{stroke-width:1.5;stroke-dasharray:none;stroke:#333;}#mermaid-1758592349615 .messageLine1{stroke-width:1.5;stroke-dasharray:2,2;stroke:#333;}#mermaid-1758592349615 #arrowhead path{fill:#333;stroke:#333;}#mermaid-1758592349615 .sequenceNumber{fill:white;}#mermaid-1758592349615 #sequencenumber{fill:#333;}#mermaid-1758592349615 #crosshead path{fill:#333;stroke:#333;}#mermaid-1758592349615 .messageText{fill:#333;stroke:none;}#mermaid-1758592349615 .labelBox{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-1758592349615 .labelText,#mermaid-1758592349615 .labelText&gt;tspan{fill:black;stroke:none;}#mermaid-1758592349615 .loopText,#mermaid-1758592349615 .loopText&gt;tspan{fill:black;stroke:none;}#mermaid-1758592349615 .loopLine{stroke-width:2px;stroke-dasharray:2,2;stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#mermaid-1758592349615 .note{stroke:#aaaa33;fill:#fff5ad;}#mermaid-1758592349615 .noteText,#mermaid-1758592349615 .noteText&gt;tspan{fill:black;stroke:none;}#mermaid-1758592349615 .activation0{fill:#f4f4f4;stroke:#666;}#mermaid-1758592349615 .activation1{fill:#f4f4f4;stroke:#666;}#mermaid-1758592349615 .activation2{fill:#f4f4f4;stroke:#666;}#mermaid-1758592349615 .actorPopupMenu{position:absolute;}#mermaid-1758592349615 .actorPopupMenuPanel{position:absolute;fill:#ECECFF;box-shadow:0px 8px 16px 0px rgba(0,0,0,0.2);filter:drop-shadow(3px 5px 2px rgb(0 0 0 / 0.4));}#mermaid-1758592349615 .actor-man line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-1758592349615 .actor-man circle,#mermaid-1758592349615 line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;stroke-width:2px;}#mermaid-1758592349615 :root{--mermaid-font-family:&quot;trebuchet ms&quot;,verdana,arial,sans-serif;}</style><g/><defs><symbol id=\"computer\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M2 2v13h20v-13h-20zm18 11h-16v-9h16v9zm-10.228 6l.466-1h3.524l.467 1h-4.457zm14.228 3h-24l2-6h2.104l-1.33 4h18.45l-1.297-4h2.073l2 6zm-5-10h-14v-7h14v7z\"/></symbol></defs><defs><symbol id=\"database\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path transform=\"scale(.5)\" d=\"M12.258.001l.256.004.255.005.253.008.251.01.249.012.247.015.246.016.242.019.241.02.239.023.236.024.233.027.231.028.229.031.225.032.223.034.22.036.217.038.214.04.211.041.208.043.205.045.201.046.198.048.194.05.191.051.187.053.183.054.18.056.175.057.172.059.168.06.163.061.16.063.155.064.15.066.074.033.073.033.071.034.07.034.069.035.068.035.067.035.066.035.064.036.064.036.062.036.06.036.06.037.058.037.058.037.055.038.055.038.053.038.052.038.051.039.05.039.048.039.047.039.045.04.044.04.043.04.041.04.04.041.039.041.037.041.036.041.034.041.033.042.032.042.03.042.029.042.027.042.026.043.024.043.023.043.021.043.02.043.018.044.017.043.015.044.013.044.012.044.011.045.009.044.007.045.006.045.004.045.002.045.001.045v17l-.001.045-.002.045-.004.045-.006.045-.007.045-.009.044-.011.045-.012.044-.013.044-.015.044-.017.043-.018.044-.02.043-.021.043-.023.043-.024.043-.026.043-.027.042-.029.042-.03.042-.032.042-.033.042-.034.041-.036.041-.037.041-.039.041-.04.041-.041.04-.043.04-.044.04-.045.04-.047.039-.048.039-.05.039-.051.039-.052.038-.053.038-.055.038-.055.038-.058.037-.058.037-.06.037-.06.036-.062.036-.064.036-.064.036-.066.035-.067.035-.068.035-.069.035-.07.034-.071.034-.073.033-.074.033-.15.066-.155.064-.16.063-.163.061-.168.06-.172.059-.175.057-.18.056-.183.054-.187.053-.191.051-.194.05-.198.048-.201.046-.205.045-.208.043-.211.041-.214.04-.217.038-.22.036-.223.034-.225.032-.229.031-.231.028-.233.027-.236.024-.239.023-.241.02-.242.019-.246.016-.247.015-.249.012-.251.01-.253.008-.255.005-.256.004-.258.001-.258-.001-.256-.004-.255-.005-.253-.008-.251-.01-.249-.012-.247-.015-.245-.016-.243-.019-.241-.02-.238-.023-.236-.024-.234-.027-.231-.028-.228-.031-.226-.032-.223-.034-.22-.036-.217-.038-.214-.04-.211-.041-.208-.043-.204-.045-.201-.046-.198-.048-.195-.05-.19-.051-.187-.053-.184-.054-.179-.056-.176-.057-.172-.059-.167-.06-.164-.061-.159-.063-.155-.064-.151-.066-.074-.033-.072-.033-.072-.034-.07-.034-.069-.035-.068-.035-.067-.035-.066-.035-.064-.036-.063-.036-.062-.036-.061-.036-.06-.037-.058-.037-.057-.037-.056-.038-.055-.038-.053-.038-.052-.038-.051-.039-.049-.039-.049-.039-.046-.039-.046-.04-.044-.04-.043-.04-.041-.04-.04-.041-.039-.041-.037-.041-.036-.041-.034-.041-.033-.042-.032-.042-.03-.042-.029-.042-.027-.042-.026-.043-.024-.043-.023-.043-.021-.043-.02-.043-.018-.044-.017-.043-.015-.044-.013-.044-.012-.044-.011-.045-.009-.044-.007-.045-.006-.045-.004-.045-.002-.045-.001-.045v-17l.001-.045.002-.045.004-.045.006-.045.007-.045.009-.044.011-.045.012-.044.013-.044.015-.044.017-.043.018-.044.02-.043.021-.043.023-.043.024-.043.026-.043.027-.042.029-.042.03-.042.032-.042.033-.042.034-.041.036-.041.037-.041.039-.041.04-.041.041-.04.043-.04.044-.04.046-.04.046-.039.049-.039.049-.039.051-.039.052-.038.053-.038.055-.038.056-.038.057-.037.058-.037.06-.037.061-.036.062-.036.063-.036.064-.036.066-.035.067-.035.068-.035.069-.035.07-.034.072-.034.072-.033.074-.033.151-.066.155-.064.159-.063.164-.061.167-.06.172-.059.176-.057.179-.056.184-.054.187-.053.19-.051.195-.05.198-.048.201-.046.204-.045.208-.043.211-.041.214-.04.217-.038.22-.036.223-.034.226-.032.228-.031.231-.028.234-.027.236-.024.238-.023.241-.02.243-.019.245-.016.247-.015.249-.012.251-.01.253-.008.255-.005.256-.004.258-.001.258.001zm-9.258 20.499v.01l.001.021.003.021.004.022.005.021.006.022.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.023.018.024.019.024.021.024.022.025.023.024.024.025.052.049.056.05.061.051.066.051.07.051.075.051.079.052.084.052.088.052.092.052.097.052.102.051.105.052.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.048.144.049.147.047.152.047.155.047.16.045.163.045.167.043.171.043.176.041.178.041.183.039.187.039.19.037.194.035.197.035.202.033.204.031.209.03.212.029.216.027.219.025.222.024.226.021.23.02.233.018.236.016.24.015.243.012.246.01.249.008.253.005.256.004.259.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.021.224-.024.22-.026.216-.027.212-.028.21-.031.205-.031.202-.034.198-.034.194-.036.191-.037.187-.039.183-.04.179-.04.175-.042.172-.043.168-.044.163-.045.16-.046.155-.046.152-.047.148-.048.143-.049.139-.049.136-.05.131-.05.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.053.083-.051.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.05.023-.024.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.023.01-.022.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.127l-.077.055-.08.053-.083.054-.085.053-.087.052-.09.052-.093.051-.095.05-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.045-.118.044-.12.043-.122.042-.124.042-.126.041-.128.04-.13.04-.132.038-.134.038-.135.037-.138.037-.139.035-.142.035-.143.034-.144.033-.147.032-.148.031-.15.03-.151.03-.153.029-.154.027-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.01-.179.008-.179.008-.181.006-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.006-.179-.008-.179-.008-.178-.01-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.027-.153-.029-.151-.03-.15-.03-.148-.031-.146-.032-.145-.033-.143-.034-.141-.035-.14-.035-.137-.037-.136-.037-.134-.038-.132-.038-.13-.04-.128-.04-.126-.041-.124-.042-.122-.042-.12-.044-.117-.043-.116-.045-.113-.045-.112-.046-.109-.047-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.05-.093-.052-.09-.051-.087-.052-.085-.053-.083-.054-.08-.054-.077-.054v4.127zm0-5.654v.011l.001.021.003.021.004.021.005.022.006.022.007.022.009.022.01.022.011.023.012.023.013.023.015.024.016.023.017.024.018.024.019.024.021.024.022.024.023.025.024.024.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.052.11.051.114.051.119.052.123.05.127.051.131.05.135.049.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.044.171.042.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.022.23.02.233.018.236.016.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.012.241-.015.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.048.139-.05.136-.049.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.051.051-.049.023-.025.023-.024.021-.025.02-.024.019-.024.018-.024.017-.024.015-.023.014-.023.013-.024.012-.022.01-.023.01-.023.008-.022.006-.022.006-.022.004-.021.004-.022.001-.021.001-.021v-4.139l-.077.054-.08.054-.083.054-.085.052-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.044-.118.044-.12.044-.122.042-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.035-.143.033-.144.033-.147.033-.148.031-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.009-.179.009-.179.007-.181.007-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.007-.179-.007-.179-.009-.178-.009-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.031-.146-.033-.145-.033-.143-.033-.141-.035-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.04-.126-.041-.124-.042-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.051-.093-.051-.09-.051-.087-.053-.085-.052-.083-.054-.08-.054-.077-.054v4.139zm0-5.666v.011l.001.02.003.022.004.021.005.022.006.021.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.024.018.023.019.024.021.025.022.024.023.024.024.025.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.051.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.043.171.043.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.021.23.02.233.018.236.017.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.013.241-.014.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.049.139-.049.136-.049.131-.051.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.049.023-.025.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.022.01-.023.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.153l-.077.054-.08.054-.083.053-.085.053-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.048-.105.048-.106.048-.109.046-.111.046-.114.046-.115.044-.118.044-.12.043-.122.043-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.034-.143.034-.144.033-.147.032-.148.032-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.024-.161.024-.162.023-.163.023-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.01-.178.01-.179.009-.179.007-.181.006-.182.006-.182.004-.184.003-.184.001-.185.001-.185-.001-.184-.001-.184-.003-.182-.004-.182-.006-.181-.006-.179-.007-.179-.009-.178-.01-.176-.01-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.023-.162-.023-.161-.024-.159-.024-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.032-.146-.032-.145-.033-.143-.034-.141-.034-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.041-.126-.041-.124-.041-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.048-.105-.048-.102-.048-.1-.05-.097-.049-.095-.051-.093-.051-.09-.052-.087-.052-.085-.053-.083-.053-.08-.054-.077-.054v4.153zm8.74-8.179l-.257.004-.254.005-.25.008-.247.011-.244.012-.241.014-.237.016-.233.018-.231.021-.226.022-.224.023-.22.026-.216.027-.212.028-.21.031-.205.032-.202.033-.198.034-.194.036-.191.038-.187.038-.183.04-.179.041-.175.042-.172.043-.168.043-.163.045-.16.046-.155.046-.152.048-.148.048-.143.048-.139.049-.136.05-.131.05-.126.051-.123.051-.118.051-.114.052-.11.052-.106.052-.101.052-.096.052-.092.052-.088.052-.083.052-.079.052-.074.051-.07.052-.065.051-.06.05-.056.05-.051.05-.023.025-.023.024-.021.024-.02.025-.019.024-.018.024-.017.023-.015.024-.014.023-.013.023-.012.023-.01.023-.01.022-.008.022-.006.023-.006.021-.004.022-.004.021-.001.021-.001.021.001.021.001.021.004.021.004.022.006.021.006.023.008.022.01.022.01.023.012.023.013.023.014.023.015.024.017.023.018.024.019.024.02.025.021.024.023.024.023.025.051.05.056.05.06.05.065.051.07.052.074.051.079.052.083.052.088.052.092.052.096.052.101.052.106.052.11.052.114.052.118.051.123.051.126.051.131.05.136.05.139.049.143.048.148.048.152.048.155.046.16.046.163.045.168.043.172.043.175.042.179.041.183.04.187.038.191.038.194.036.198.034.202.033.205.032.21.031.212.028.216.027.22.026.224.023.226.022.231.021.233.018.237.016.241.014.244.012.247.011.25.008.254.005.257.004.26.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.022.224-.023.22-.026.216-.027.212-.028.21-.031.205-.032.202-.033.198-.034.194-.036.191-.038.187-.038.183-.04.179-.041.175-.042.172-.043.168-.043.163-.045.16-.046.155-.046.152-.048.148-.048.143-.048.139-.049.136-.05.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.05.051-.05.023-.025.023-.024.021-.024.02-.025.019-.024.018-.024.017-.023.015-.024.014-.023.013-.023.012-.023.01-.023.01-.022.008-.022.006-.023.006-.021.004-.022.004-.021.001-.021.001-.021-.001-.021-.001-.021-.004-.021-.004-.022-.006-.021-.006-.023-.008-.022-.01-.022-.01-.023-.012-.023-.013-.023-.014-.023-.015-.024-.017-.023-.018-.024-.019-.024-.02-.025-.021-.024-.023-.024-.023-.025-.051-.05-.056-.05-.06-.05-.065-.051-.07-.052-.074-.051-.079-.052-.083-.052-.088-.052-.092-.052-.096-.052-.101-.052-.106-.052-.11-.052-.114-.052-.118-.051-.123-.051-.126-.051-.131-.05-.136-.05-.139-.049-.143-.048-.148-.048-.152-.048-.155-.046-.16-.046-.163-.045-.168-.043-.172-.043-.175-.042-.179-.041-.183-.04-.187-.038-.191-.038-.194-.036-.198-.034-.202-.033-.205-.032-.21-.031-.212-.028-.216-.027-.22-.026-.224-.023-.226-.022-.231-.021-.233-.018-.237-.016-.241-.014-.244-.012-.247-.011-.25-.008-.254-.005-.257-.004-.26-.001-.26.001z\"/></symbol></defs><defs><symbol id=\"clock\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M12 2c5.514 0 10 4.486 10 10s-4.486 10-10 10-10-4.486-10-10 4.486-10 10-10zm0-2c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm5.848 12.459c.202.038.202.333.001.372-1.907.361-6.045 1.111-6.547 1.111-.719 0-1.301-.582-1.301-1.301 0-.512.77-5.447 1.125-7.445.034-.192.312-.181.343.014l.985 6.238 5.394 1.011z\"/></symbol></defs><defs><marker id=\"arrowhead\" refX=\"7.9\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto-start-reverse\"><path d=\"M -1 0 L 10 5 L 0 10 z\"/></marker></defs><defs><marker id=\"crosshead\" markerWidth=\"15\" markerHeight=\"8\" orient=\"auto\" refX=\"4\" refY=\"4.5\"><path fill=\"none\" stroke=\"#000000\" stroke-width=\"1pt\" d=\"M 1,2 L 6,7 M 6,2 L 1,7\" style=\"stroke-dasharray: 0, 0;\"/></marker></defs><defs><marker id=\"filled-head\" refX=\"15.5\" refY=\"7\" markerWidth=\"20\" markerHeight=\"28\" orient=\"auto\"><path d=\"M 18,7 L9,13 L14,7 L9,1 Z\"/></marker></defs><defs><marker id=\"sequencenumber\" refX=\"15\" refY=\"15\" markerWidth=\"60\" markerHeight=\"40\" orient=\"auto\"><circle cx=\"15\" cy=\"15\" r=\"6\"/></marker></defs><g><rect x=\"247\" y=\"75\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"180\" height=\"39\" class=\"note\"/><text x=\"337\" y=\"80\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"337\">Initialize messages = []</tspan></text></g><g><rect x=\"229.5\" y=\"124\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"215\" height=\"39\" class=\"note\"/><text x=\"337\" y=\"129\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"337\">Define tool calls and names</tspan></text></g><g><rect x=\"225.5\" y=\"585\" fill=\"#EDF2AE\" stroke=\"#666\" width=\"223\" height=\"39\" class=\"note\"/><text x=\"337\" y=\"590\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"noteText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"337\">Grok requests tool execution</tspan></text></g><g><line x1=\"208\" y1=\"634\" x2=\"856\" y2=\"634\" class=\"loopLine\"/><line x1=\"856\" y1=\"634\" x2=\"856\" y2=\"896\" class=\"loopLine\"/><line x1=\"208\" y1=\"896\" x2=\"856\" y2=\"896\" class=\"loopLine\"/><line x1=\"208\" y1=\"634\" x2=\"208\" y2=\"896\" class=\"loopLine\"/><polygon points=\"208,634 258,634 258,647 249.6,654 208,654\" class=\"labelBox\"/><text x=\"233\" y=\"647\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"labelText\" style=\"font-size: 16px; font-weight: 400;\">loop</text><text x=\"557\" y=\"652\" text-anchor=\"middle\" class=\"loopText\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"557\">[For each tool in tool_calls]</tspan></text></g><g><line x1=\"198\" y1=\"539\" x2=\"866\" y2=\"539\" class=\"loopLine\"/><line x1=\"866\" y1=\"539\" x2=\"866\" y2=\"906\" class=\"loopLine\"/><line x1=\"198\" y1=\"906\" x2=\"866\" y2=\"906\" class=\"loopLine\"/><line x1=\"198\" y1=\"539\" x2=\"198\" y2=\"906\" class=\"loopLine\"/><polygon points=\"198,539 248,539 248,552 239.6,559 198,559\" class=\"labelBox\"/><text x=\"223\" y=\"552\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"labelText\" style=\"font-size: 16px; font-weight: 400;\">alt</text><text x=\"557\" y=\"557\" text-anchor=\"middle\" class=\"loopText\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"557\">[Response contains tool_call]</tspan></text></g><g><line x1=\"64\" y1=\"968\" x2=\"464\" y2=\"968\" class=\"loopLine\"/><line x1=\"464\" y1=\"968\" x2=\"464\" y2=\"1178\" class=\"loopLine\"/><line x1=\"64\" y1=\"1178\" x2=\"464\" y2=\"1178\" class=\"loopLine\"/><line x1=\"64\" y1=\"968\" x2=\"64\" y2=\"1178\" class=\"loopLine\"/><polygon points=\"64,968 114,968 114,981 105.6,988 64,988\" class=\"labelBox\"/><text x=\"89\" y=\"981\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"labelText\" style=\"font-size: 16px; font-weight: 400;\">alt</text><text x=\"289\" y=\"986\" text-anchor=\"middle\" class=\"loopText\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"289\">[User provides new request]</tspan></text></g><g><line x1=\"54\" y1=\"493\" x2=\"876\" y2=\"493\" class=\"loopLine\"/><line x1=\"876\" y1=\"493\" x2=\"876\" y2=\"1344\" class=\"loopLine\"/><line x1=\"54\" y1=\"1344\" x2=\"876\" y2=\"1344\" class=\"loopLine\"/><line x1=\"54\" y1=\"493\" x2=\"54\" y2=\"1344\" class=\"loopLine\"/><polygon points=\"54,493 104,493 104,506 95.6,513 54,513\" class=\"labelBox\"/><text x=\"79\" y=\"506\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"labelText\" style=\"font-size: 16px; font-weight: 400;\">loop</text><text x=\"490\" y=\"511\" text-anchor=\"middle\" class=\"loopText\" style=\"font-size: 16px; font-weight: 400;\"><tspan x=\"490\">[Continuous Processing]</tspan></text></g><text x=\"205\" y=\"178\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Send new user request</text><line x1=\"76\" y1=\"215\" x2=\"333\" y2=\"215\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"338\" y=\"230\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Add user message to messages[]</text><path d=\"M 338,267 C 398,257 398,297 338,287\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"490\" y=\"312\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">send_request_to_grok(messages)</text><line x1=\"338\" y1=\"349\" x2=\"641\" y2=\"349\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"493\" y=\"364\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Response with potential tool_calls</text><line x1=\"644\" y1=\"401\" x2=\"341\" y2=\"401\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"338\" y=\"416\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Add assistant response to messages[]</text><path d=\"M 338,453 C 398,443 398,483 338,473\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"590\" y=\"685\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Execute tool(arguments)</text><line x1=\"338\" y1=\"722\" x2=\"841\" y2=\"722\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"593\" y=\"737\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Return tool_call_result</text><line x1=\"844\" y1=\"774\" x2=\"341\" y2=\"774\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"338\" y=\"789\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Add tool_call_result to messages[]</text><path d=\"M 338,826 C 398,816 398,856 338,846\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"208\" y=\"921\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Check for new user request</text><line x1=\"336\" y1=\"958\" x2=\"79\" y2=\"958\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"205\" y=\"1019\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">New user request</text><line x1=\"76\" y1=\"1056\" x2=\"333\" y2=\"1056\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"338\" y=\"1071\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Add user message to messages[]</text><path d=\"M 338,1108 C 398,1098 398,1138 338,1128\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"490\" y=\"1193\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">send_request_to_grok(messages)</text><line x1=\"338\" y1=\"1230\" x2=\"641\" y2=\"1230\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"493\" y=\"1245\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Updated response</text><line x1=\"644\" y1=\"1282\" x2=\"341\" y2=\"1282\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"208\" y=\"1297\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">Print/display response</text><line x1=\"336\" y1=\"1334\" x2=\"79\" y2=\"1334\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/></svg>"
            ],
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import SVG, display\n",
        "\n",
        "# Use the raw GitHub URL\n",
        "url = \"https://raw.githubusercontent.com/enoch-sit/publicimages/main/toolcalls.svg\"\n",
        "display(SVG(url=url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "api_client"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "from xai_sdk import Client\n",
        "from xai_sdk.chat import tool, tool_result, user\n",
        "\n",
        "client = Client(api_key=os.getenv('XAI_API_KEY'))\n",
        "chat = client.chat.create(model=\"grok-3-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prep_tools"
      },
      "source": [
        "### Preparation - Define tool functions and function mapping\n",
        "Define tool functions as callback functions to be called when model requests them in response.\n",
        "Normally, these functions would either retrieve data from a database, or call another API endpoint, or perform some actions. For demonstration purposes, we hardcode to return 59¬∞ Fahrenheit/15¬∞ Celsius as the temperature, and 15,000 feet as the cloud ceiling.\n",
        "The parameters definition will be sent in the initial request to Grok, so Grok knows what tools and parameters are available to be called.\n",
        "To reduce human error, you can define the tools partially using Pydantic.\n",
        "\n",
        "The get_current_ceiling function from the xAI Grok API tutorial is an example tool designed to retrieve the current cloud ceiling height for a specified location, which is directly related to weather as a key meteorological measurement. In weather contexts, a cloud ceiling refers to the height above the ground (or water) of the base of the lowest layer of clouds that covers more than half the sky (often more than 50% or 4/8 oktas). This data is commonly reported in aviation weather reports (e.g., METARs) to assess visibility, flight safety, and conditions like overcast skies, but it can also inform general forecasting for precipitation, fog, or atmospheric stability. In the tutorial, the function is hardcoded for demonstration (returning a fixed value like 15,000 feet with a \"broken\" cloud type), but in practice, it would query a weather API or database to provide real-time cloud ceiling data as part of broader weather too\n",
        "\n",
        "#### Function definition using Pydantic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pydantic_def"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class TemperatureRequest(BaseModel):\n",
        "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
        "    unit: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
        "        \"fahrenheit\", description=\"Temperature unit\"\n",
        "    )\n",
        "\n",
        "class CeilingRequest(BaseModel):\n",
        "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
        "\n",
        "def get_current_temperature(request: TemperatureRequest):\n",
        "    temperature = 59 if request.unit.lower() == \"fahrenheit\" else 15\n",
        "    return {\n",
        "        \"location\": request.location,\n",
        "        \"temperature\": temperature,\n",
        "        \"unit\": request.unit,\n",
        "    }\n",
        "\n",
        "def get_current_ceiling(request: CeilingRequest):\n",
        "    return {\n",
        "        \"location\": request.location,\n",
        "        \"ceiling\": 15000,\n",
        "        \"ceiling_type\": \"broken\",\n",
        "        \"unit\": \"ft\",\n",
        "    }\n",
        "\n",
        "# Generate the JSON schema from the Pydantic models\n",
        "\n",
        "get_current_temperature_schema = TemperatureRequest.model_json_schema()\n",
        "get_current_ceiling_schema = CeilingRequest.model_json_schema()\n",
        "\n",
        "# Definition of parameters with Pydantic JSON schema\n",
        "\n",
        "tool_definitions = [\n",
        "    tool(\n",
        "        name=\"get_current_temperature\",\n",
        "        description=\"Get the current temperature in a given location\",\n",
        "        parameters=get_current_temperature_schema,\n",
        "    ),\n",
        "    tool(\n",
        "        name=\"get_current_ceiling\",\n",
        "        description=\"Get the current cloud ceiling in a given location\",\n",
        "        parameters=get_current_ceiling_schema,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raw_dict_def"
      },
      "source": [
        "#### Function definition using raw dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "raw_dict_code"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "def get_current_temperature(location: str, unit: Literal[\"celsius\", \"fahrenheit\"] = \"fahrenheit\"):\n",
        "    temperature = 59 if unit == \"fahrenheit\" else 15\n",
        "    return {\n",
        "        \"location\": location,\n",
        "        \"temperature\": temperature,\n",
        "        \"unit\": unit,\n",
        "    }\n",
        "\n",
        "def get_current_ceiling(location: str):\n",
        "    return {\n",
        "        \"location\": location,\n",
        "        \"ceiling\": 15000,\n",
        "        \"ceiling_type\": \"broken\",\n",
        "        \"unit\": \"ft\",\n",
        "    }\n",
        "\n",
        "# Raw dictionary definition of parameters\n",
        "\n",
        "tool_definitions = [\n",
        "    tool(\n",
        "        name=\"get_current_temperature\",\n",
        "        description=\"Get the current temperature in a given location\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                },\n",
        "                \"unit\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                    \"default\": \"fahrenheit\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        },\n",
        "    ),\n",
        "    tool(\n",
        "        name=\"get_current_ceiling\",\n",
        "        description=\"Get the current cloud ceiling in a given location\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        },\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tools_map"
      },
      "source": [
        "Create a string -> function mapping, so we can call the function when model sends it's name. e.g."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tools_map_code"
      },
      "outputs": [],
      "source": [
        "tools_map = {\n",
        "    \"get_current_temperature\": get_current_temperature,\n",
        "    \"get_current_ceiling\": get_current_ceiling,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "### 1. Send initial message\n",
        "With all the functions defined, it's time to send our API request to Grok!\n",
        "Now before we send it over, let's look at how the generic request body for a new task looks like.\n",
        "Here we assume a previous tool call has Note how the tool call is referenced three times:\n",
        "\n",
        "* By id and name in \"Mesage History\" assistant's first response\n",
        "\n",
        "* By tool_call_id in \"Message History\" tool's content\n",
        "\n",
        "* In the tools field of the request body\n",
        "\n",
        "Now we compose the request messages in the request body and send it over to Grok. Grok should return a response that asks us for a tool call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "send_initial",
        "outputId": "bac700c6-2057-4c50-d9bb-b609c26d1e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[id: \"call_81007743\"\n",
            "function {\n",
            "  name: \"get_current_temperature\"\n",
            "  arguments: \"{\\\"location\\\":\\\"San Francisco, CA\\\"}\"\n",
            "}\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "chat = client.chat.create(\n",
        "    model=\"grok-3-mini\",\n",
        "    tools=tool_definitions,\n",
        "    tool_choice=\"auto\",\n",
        ")\n",
        "chat.append(user(\"What's the temperature like in San Francisco?\"))\n",
        "response = chat.sample()\n",
        "\n",
        "# You can inspect the response tool calls which contains a tool call\n",
        "\n",
        "print(response.tool_calls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "### 2. Run tool functions if Grok asks tool call and append function returns to message\n",
        "We retrieve the tool function names and arguments that Grok wants to call, run the functions, and add the result to messages.\n",
        "At this point, you can choose to only respond to tool call with results or add a new user message request.\n",
        "The tool message would contain the following:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"role\": \"tool\",\n",
        "    \"content\": <json string of tool function's returned object>,\n",
        "    \"tool_call_id\": <tool_call.id included in the tool call response by Grok>,\n",
        "}\n",
        "```\n",
        "\n",
        "The request body that we try to assemble and send back to Grok. Note it looks slightly different from the new task request body:\n",
        "The corresponding code to append messages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "run_tools"
      },
      "outputs": [],
      "source": [
        "# Append assistant message including tool calls to messages\n",
        "chat.append(response)\n",
        "\n",
        "# Check if there is any tool calls in response body\n",
        "\n",
        "# You can also wrap this in a function to make the code cleaner\n",
        "\n",
        "if response.tool_calls:\n",
        "    for tool_call in response.tool_calls:\n",
        "\n",
        "        # Get the tool function name and arguments Grok wants to call\n",
        "        function_name = tool_call.function.name\n",
        "        function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "        # Call one of the tool function defined earlier with arguments\n",
        "        result = tools_map[function_name](**function_args)\n",
        "\n",
        "        # Append the result from tool function call to the chat message history\n",
        "        chat.append(tool_result(json.dumps(result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "### 3. Send the tool function returns back to the model to get the response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "send_back",
        "outputId": "5bef9fcc-c348-4feb-c7b2-7bd86a06bf06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current temperature in San Francisco, CA is 59¬∞F.\n"
          ]
        }
      ],
      "source": [
        "response = chat.sample()\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "### 4. (Optional) Continue the conversation\n",
        "You can continue the conversation following Step 2. Otherwise you can terminate.\n",
        "\n",
        "### Function calling modes\n",
        "By default, the model will automatically decide whether a function call is necessary and select which functions to call, as determined by the¬†tool_choice: \"auto\"¬†setting.\n",
        "We offer three ways to customize the default behavior:\n",
        "\n",
        "1. To force the model to always call one or more functions, you can set¬†tool_choice: \"required\". The model will then always call function. Note this could force the model to hallucinate parameters.\n",
        "\n",
        "2. To force the model to call a specific function, you can set¬†tool_choice: {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}.\n",
        "\n",
        "3. To disable function calling and force the model to only generate a user-facing message, you can either provide no tools, or set¬†tool_choice: \"none\".\n",
        "\n",
        "### Parallel function calling\n",
        "By default, parallel function calling is enabled, so you can process multiple function calls in one request/response cycle. When two or more tool calls are required, all of the tool call requests will be included in the response body. You can disable it by setting parallel_function_calling : \"false\"."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
