{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Guide to Pydantic for LLM Workflows\n",
    "\n",
    "This notebook provides a hands-on guide to using Pydantic for structuring and validating LLM outputs. We'll explore core concepts, practical examples, and best practices for building robust weather data processing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages and set up our AWS Bedrock connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pydantic boto3 langchain-aws email-validator python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime, date\n",
    "from typing import Optional, List, Literal\n",
    "from enum import Enum\n",
    "\n",
    "from pydantic import BaseModel, EmailStr, Field, HttpUrl, ValidationError, validator\n",
    "from langchain_aws import ChatBedrock\n",
    "from google.colab import userdata\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AWS credentials using Colab secrets\n",
    "AWS_ACCESS_KEY_ID = userdata.get('awsid')\n",
    "AWS_SECRET_ACCESS_KEY = userdata.get('awssecret')\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=AWS_REGION,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "# Set up the Bedrock model (using Amazon Nova Lite for cost-effectiveness)\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=\"amazon.nova-lite-v1:0\",\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✓ AWS Bedrock client initialized\")\n",
    "print(f\"✓ Using model: amazon.nova-lite-v1:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Context\n",
    "\n",
    "### The Challenge of Structured Output from LLMs\n",
    "\n",
    "When working with Large Language Models (LLMs), one of the fundamental challenges is obtaining structured, predictable output that can be reliably processed by downstream systems. While you can simply ask an LLM to format its response in a particular way (like JSON), the results are often unpredictable:\n",
    "\n",
    "**Common Issues:**\n",
    "- Extra text outside the JSON structure (e.g., \"Here's the JSON output you requested:\")\n",
    "- Markdown formatting (triple backticks around JSON)\n",
    "- Missing or incorrectly formatted fields\n",
    "- Invalid data types\n",
    "\n",
    "### Why Pydantic?\n",
    "\n",
    "Pydantic provides a robust solution by allowing you to:\n",
    "1. Define explicit data models with field names and types\n",
    "2. Validate LLM responses against these models\n",
    "3. Catch and handle validation errors systematically\n",
    "4. Ensure data consistency throughout your application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Pydantic Models\n",
    "\n",
    "Let's start by creating simple Pydantic models and understanding how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Your First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherReport(BaseModel):\n",
    "    station_id: str\n",
    "    location: str\n",
    "    temperature: float\n",
    "    conditions: str\n",
    "\n",
    "# Valid data\n",
    "weather_report = WeatherReport(\n",
    "    station_id=\"KORD\",\n",
    "    location=\"Chicago, IL\",\n",
    "    temperature=72.5,\n",
    "    conditions=\"Partly cloudy with light winds\"\n",
    ")\n",
    "\n",
    "print(\"Valid weather report:\")\n",
    "print(weather_report)\n",
    "print(f\"\\nStation ID: {weather_report.station_id}\")\n",
    "print(f\"Location: {weather_report.location}\")\n",
    "print(f\"Temperature: {weather_report.temperature}°F\")\n",
    "print(f\"Conditions: {weather_report.conditions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invalid temperature - string instead of float\n",
    "try:\n",
    "    invalid_report = WeatherReport(\n",
    "        station_id=\"KLAX\",\n",
    "        location=\"Los Angeles, CA\",\n",
    "        temperature=\"very hot\",  # Invalid format - should be float\n",
    "        conditions=\"Sunny and clear\"\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(\"Validation Error Occurred:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Alert System Example\n",
    "\n",
    "Let's build a more realistic model for a weather alert and warning system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertType(str, Enum):\n",
    "    TORNADO = \"tornado\"\n",
    "    THUNDERSTORM = \"thunderstorm\"\n",
    "    FLOOD = \"flood\"\n",
    "    HEAT = \"heat\"\n",
    "    WINTER_STORM = \"winter_storm\"\n",
    "    HIGH_WIND = \"high_wind\"\n",
    "\n",
    "class WeatherAlert(BaseModel):\n",
    "    alert_id: str = Field(min_length=5, max_length=20)\n",
    "    station_id: str = Field(pattern=r\"^[A-Z]{4}$\")\n",
    "    county: str = Field(min_length=2, max_length=50)\n",
    "    alert_type: AlertType\n",
    "    description: str = Field(min_length=10, max_length=1000)\n",
    "    event_id: Optional[str] = Field(\n",
    "        default=None,\n",
    "        pattern=r\"^EVT-\\d{8}$\",\n",
    "        description=\"Format: EVT-12345678\"\n",
    "    )\n",
    "    issued_date: Optional[date] = None\n",
    "    affected_areas: List[str] = Field(default_factory=list, max_items=10)\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"alert_id\": \"ALERT12345\",\n",
    "                \"station_id\": \"KORD\",\n",
    "                \"county\": \"Cook County\",\n",
    "                \"alert_type\": \"thunderstorm\",\n",
    "                \"description\": \"Severe thunderstorm warning with hail up to quarter size and winds up to 60 mph\",\n",
    "                \"event_id\": \"EVT-20240315\",\n",
    "                \"issued_date\": \"2024-03-15\",\n",
    "                \"affected_areas\": [\"Chicago\", \"Evanston\", \"Oak Park\"]\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Create a weather alert\n",
    "alert = WeatherAlert(\n",
    "    alert_id=\"ALERT12345\",\n",
    "    station_id=\"KORD\",\n",
    "    county=\"Cook County\",\n",
    "    alert_type=AlertType.THUNDERSTORM,\n",
    "    description=\"Severe thunderstorm warning with hail up to quarter size and winds up to 60 mph\",\n",
    "    event_id=\"EVT-20240315\"\n",
    ")\n",
    "\n",
    "print(\"Weather Alert Created:\")\n",
    "print(json.dumps(alert.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Coercion\n",
    "\n",
    "Pydantic automatically converts compatible data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherStation(BaseModel):\n",
    "    station_id: int\n",
    "    elevation: float\n",
    "    is_active: bool\n",
    "    \n",
    "# String to int/float/bool conversion\n",
    "station = WeatherStation(\n",
    "    station_id=\"12345\",      # Converted to int\n",
    "    elevation=\"1025.5\",      # Converted to float\n",
    "    is_active=\"true\"         # Converted to bool\n",
    ")\n",
    "\n",
    "print(f\"Station ID: {station.station_id} (type: {type(station.station_id).__name__})\")\n",
    "print(f\"Elevation: {station.elevation} ft (type: {type(station.elevation).__name__})\")\n",
    "print(f\"Is Active: {station.is_active} (type: {type(station.is_active).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherObservation(BaseModel):\n",
    "    station_name: str\n",
    "    observer_email: EmailStr\n",
    "    conditions: str\n",
    "    temperature: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Temperature in Fahrenheit, range -50 to 130\",\n",
    "        ge=-50,\n",
    "        le=130\n",
    "    )\n",
    "    observation_date: Optional[date] = None\n",
    "\n",
    "# From JSON string to model\n",
    "json_data = '''\n",
    "{\n",
    "    \"station_name\": \"Downtown Weather Station\",\n",
    "    \"observer_email\": \"weather.observer@nws.gov\",\n",
    "    \"conditions\": \"Clear skies with light winds from the northwest\",\n",
    "    \"temperature\": 68,\n",
    "    \"observation_date\": \"2024-03-10\"\n",
    "}\n",
    "'''\n",
    "\n",
    "# Method 1: Parse JSON, then create model\n",
    "data_dict = json.loads(json_data)\n",
    "observation1 = WeatherObservation(**data_dict)\n",
    "print(\"Method 1 - From dict:\")\n",
    "print(observation1)\n",
    "\n",
    "# Method 2: Direct validation from JSON (preferred)\n",
    "observation2 = WeatherObservation.model_validate_json(json_data)\n",
    "print(\"\\nMethod 2 - Direct from JSON:\")\n",
    "print(observation2)\n",
    "\n",
    "# To JSON\n",
    "json_output = observation2.model_dump_json(indent=2)\n",
    "print(\"\\nBack to JSON:\")\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validating LLM Responses\n",
    "\n",
    "Now let's see how to use Pydantic to validate and structure LLM outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Forecast Validation System Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfidenceLevel(str, Enum):\n",
    "    VERY_HIGH = \"very_high\"\n",
    "    HIGH = \"high\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LOW = \"low\"\n",
    "    VERY_LOW = \"very_low\"\n",
    "\n",
    "class ForecastIssue(str, Enum):\n",
    "    NONE = \"none\"\n",
    "    TEMPERATURE_ANOMALY = \"temperature_anomaly\"\n",
    "    PRECIPITATION_MISMATCH = \"precipitation_mismatch\"\n",
    "    PRESSURE_INCONSISTENT = \"pressure_inconsistent\"\n",
    "    WIND_DIRECTION_ERROR = \"wind_direction_error\"\n",
    "    HUMIDITY_OUT_OF_RANGE = \"humidity_out_of_range\"\n",
    "    SEVERE_WEATHER_MISSED = \"severe_weather_missed\"\n",
    "\n",
    "class ForecastValidation(BaseModel):\n",
    "    forecast_id: str\n",
    "    is_accurate: bool\n",
    "    confidence: ConfidenceLevel\n",
    "    issues: List[ForecastIssue] = Field(default_factory=list)\n",
    "    accuracy_score: float = Field(ge=0.0, le=1.0)\n",
    "    flagged_parameters: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        max_items=10,\n",
    "        description=\"Specific weather parameters that triggered validation flags\"\n",
    "    )\n",
    "    recommended_action: Literal[\"publish\", \"review\", \"revise\", \"escalate\"]\n",
    "    explanation: str = Field(\n",
    "        min_length=20,\n",
    "        max_length=500,\n",
    "        description=\"Brief explanation of the validation result\"\n",
    "    )\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"forecast_id\": \"FCST_12345\",\n",
    "                \"is_accurate\": False,\n",
    "                \"confidence\": \"medium\",\n",
    "                \"issues\": [\"temperature_anomaly\", \"precipitation_mismatch\"],\n",
    "                \"accuracy_score\": 0.72,\n",
    "                \"flagged_parameters\": [\"high_temp: 95°F\", \"chance_of_rain: 80%\"],\n",
    "                \"recommended_action\": \"review\",\n",
    "                \"explanation\": \"Temperature prediction significantly above seasonal average and precipitation forecast conflicts with pressure readings\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Display the schema\n",
    "schema = ForecastValidation.model_json_schema()\n",
    "print(\"ForecastValidation Schema:\")\n",
    "print(json.dumps(schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Function with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_forecast_response(llm_response: str) -> tuple[ForecastValidation | None, str | None]:\n",
    "    \"\"\"Validate LLM forecast validation response with detailed error handling.\"\"\"\n",
    "    try:\n",
    "        # First attempt: direct validation\n",
    "        result = ForecastValidation.model_validate_json(llm_response)\n",
    "        return result, None\n",
    "    except json.JSONDecodeError as e:\n",
    "        return None, f\"Invalid JSON format: {str(e)}\"\n",
    "    except ValidationError as e:\n",
    "        # Extract specific validation errors\n",
    "        error_details = []\n",
    "        for error in e.errors():\n",
    "            field = \" -> \".join(str(x) for x in error[\"loc\"])\n",
    "            message = error[\"msg\"]\n",
    "            error_details.append(f\"{field}: {message}\")\n",
    "        return None, \"; \".join(error_details)\n",
    "\n",
    "# Test with valid data\n",
    "valid_response = '''\n",
    "{\n",
    "    \"forecast_id\": \"FCST_12345\",\n",
    "    \"is_accurate\": true,\n",
    "    \"confidence\": \"high\",\n",
    "    \"issues\": [\"none\"],\n",
    "    \"accuracy_score\": 0.89,\n",
    "    \"flagged_parameters\": [],\n",
    "    \"recommended_action\": \"publish\",\n",
    "    \"explanation\": \"All weather parameters are within expected ranges and consistent with current atmospheric conditions\"\n",
    "}\n",
    "'''\n",
    "\n",
    "result, error = validate_forecast_response(valid_response)\n",
    "if result:\n",
    "    print(\"✓ Validation successful!\")\n",
    "    print(f\"Forecast ID: {result.forecast_id}\")\n",
    "    print(f\"Accurate: {result.is_accurate}\")\n",
    "    print(f\"Action: {result.recommended_action}\")\n",
    "else:\n",
    "    print(f\"✗ Validation failed: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with LLM - Weather Forecast Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forecast_validation_prompt(forecast_data: str, forecast_id: str) -> str:\n",
    "    \"\"\"Create a schema-based prompt for weather forecast validation.\"\"\"\n",
    "    schema = ForecastValidation.model_json_schema()\n",
    "    \n",
    "    prompt = f\"\"\"You are a weather forecast validation AI. Analyze the following forecast for accuracy and consistency.\n",
    "\n",
    "FORECAST TO ANALYZE:\n",
    "ID: {forecast_id}\n",
    "Data: {forecast_data}\n",
    "\n",
    "OUTPUT REQUIREMENTS:\n",
    "Provide your analysis as a valid JSON object that strictly conforms to this schema:\n",
    "\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. Return ONLY valid JSON - no markdown formatting, no explanatory text\n",
    "2. Ensure all required fields are present\n",
    "3. Follow exact field types and constraints\n",
    "4. accuracy_score must be between 0.0 and 1.0\n",
    "5. confidence must be one of: very_high, high, medium, low, very_low\n",
    "\n",
    "Begin your response with {{ and end with }}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Test forecast data\n",
    "test_forecast = \"Tomorrow: High 110°F, Low 32°F, 99% chance of snow, winds calm from all directions\"\n",
    "forecast_id = \"FCST_001\"\n",
    "\n",
    "prompt = create_forecast_validation_prompt(test_forecast, forecast_id)\n",
    "print(\"Prompt sent to LLM:\")\n",
    "print(\"=\" * 60)\n",
    "print(prompt)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get LLM response\n",
    "response = llm.invoke(prompt)\n",
    "llm_output = response.content\n",
    "\n",
    "print(\"\\nLLM Response:\")\n",
    "print(\"=\" * 60)\n",
    "print(llm_output)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Validate the response\n",
    "result, error = validate_forecast_response(llm_output)\n",
    "\n",
    "if result:\n",
    "    print(\"\\n✓ Validation SUCCESSFUL!\")\n",
    "    print(\"\\nParsed Result:\")\n",
    "    print(json.dumps(result.model_dump(), indent=2, default=str))\n",
    "else:\n",
    "    print(f\"\\n✗ Validation FAILED: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Retry Logic with Error Feedback\n",
    "\n",
    "LLMs don't always get the format right on the first try. Let's implement a retry mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_llm_response_with_retry(\n",
    "    prompt: str,\n",
    "    data_model: type[BaseModel],\n",
    "    max_retries: int = 3,\n",
    ") -> BaseModel | None:\n",
    "    \"\"\"\n",
    "    Validate LLM response with automatic retry on validation errors.\n",
    "    \"\"\"\n",
    "    # Initial call\n",
    "    response = llm.invoke(prompt)\n",
    "    llm_response = response.content\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Attempt validation\n",
    "            validated_data = data_model.model_validate_json(llm_response)\n",
    "            print(f\"✓ Validation successful on attempt {attempt + 1}\")\n",
    "            return validated_data\n",
    "            \n",
    "        except (ValidationError, json.JSONDecodeError) as e:\n",
    "            print(f\"✗ Attempt {attempt + 1} failed: {str(e)[:200]}...\")\n",
    "            \n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"Max retries reached. Validation failed.\")\n",
    "                return None\n",
    "            \n",
    "            # Create retry prompt with error feedback\n",
    "            retry_prompt = f\"\"\"VALIDATION ERROR OCCURRED\n",
    "\n",
    "Original Prompt:\n",
    "{prompt}\n",
    "\n",
    "Your Previous Response:\n",
    "{llm_response}\n",
    "\n",
    "Error Message:\n",
    "{str(e)}\n",
    "\n",
    "Please fix the error and provide a corrected response. Remember:\n",
    "- Return ONLY valid JSON\n",
    "- No markdown formatting or extra text\n",
    "- Match the exact schema requirements\n",
    "- Begin with {{ and end with }}\"\"\"\n",
    "            \n",
    "            # Retry with error feedback\n",
    "            response = llm.invoke(retry_prompt)\n",
    "            llm_response = response.content\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test with retry logic\n",
    "print(\"Testing retry logic...\\n\")\n",
    "result = validate_llm_response_with_retry(\n",
    "    prompt=create_forecast_validation_prompt(test_forecast, forecast_id),\n",
    "    data_model=ForecastValidation,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(\"\\nFinal validated result:\")\n",
    "    print(json.dumps(result.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Example: Weather Station Data Analysis\n",
    "\n",
    "Let's build a more complex model for analyzing weather station data and climate patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meteorologist(BaseModel):\n",
    "    name: str\n",
    "    station: str\n",
    "    email: Optional[EmailStr] = None\n",
    "\n",
    "class ClimateDataAnalysis(BaseModel):\n",
    "    report_title: str = Field(min_length=10, max_length=300)\n",
    "    meteorologists: List[Meteorologist] = Field(min_items=1, max_items=20)\n",
    "    analysis_date: date\n",
    "    summary: str = Field(min_length=100, max_length=2000)\n",
    "    weather_patterns: List[str] = Field(min_items=3, max_items=10)\n",
    "    methodology: str = Field(min_length=50, max_length=1000)\n",
    "    key_findings: List[str] = Field(\n",
    "        min_items=2,\n",
    "        max_items=5,\n",
    "        description=\"Main weather patterns or climate observations\"\n",
    "    )\n",
    "    data_limitations: List[str] = Field(min_items=1, max_items=5)\n",
    "    accuracy_score: float = Field(\n",
    "        ge=0.0,\n",
    "        le=10.0,\n",
    "        description=\"Estimated forecast accuracy (0-10)\"\n",
    "    )\n",
    "    measurements_analyzed: int = Field(ge=0)\n",
    "    related_stations: List[HttpUrl] = Field(default_factory=list, max_items=10)\n",
    "\n",
    "# Display schema\n",
    "print(\"Climate Data Analysis Schema:\")\n",
    "print(json.dumps(ClimateDataAnalysis.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_climate_analysis_prompt(weather_summary: str) -> str:\n",
    "    \"\"\"Create a schema-based prompt for climate data analysis.\"\"\"\n",
    "    schema = ClimateDataAnalysis.model_json_schema()\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert meteorologist. Analyze the following weather data summary and extract structured information.\n",
    "\n",
    "WEATHER DATA SUMMARY:\n",
    "{weather_summary}\n",
    "\n",
    "OUTPUT REQUIREMENTS:\n",
    "Provide your analysis as a valid JSON object that strictly conforms to this schema:\n",
    "\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "1. Return ONLY valid JSON - no markdown formatting, no explanatory text\n",
    "2. Ensure all required fields are present\n",
    "3. Follow exact field types and constraints\n",
    "4. Arrays must contain the specified minimum number of items\n",
    "5. Dates must be in YYYY-MM-DD format\n",
    "6. Make reasonable inferences based on the weather data\n",
    "7. For missing information, use plausible meteorological estimates\n",
    "\n",
    "Begin your response with {{ and end with }}\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Sample weather summary\n",
    "sample_summary = \"\"\"Weather stations across the Midwest have recorded unprecedented temperature variations over the past month.\n",
    "Our analysis of 15 monitoring stations shows a 23% increase in temperature fluctuations compared to historical averages.\n",
    "The data reveals significant correlation between wind patterns and local temperature variations. Precipitation measurements\n",
    "indicate irregular rainfall distribution with some areas experiencing 40% above normal levels while others report drought conditions.\"\"\"\n",
    "\n",
    "prompt = create_climate_analysis_prompt(sample_summary)\n",
    "result = validate_llm_response_with_retry(\n",
    "    prompt=prompt,\n",
    "    data_model=ClimateDataAnalysis,\n",
    "    max_retries=3\n",
    ")\n",
    "\n",
    "if result:\n",
    "    print(\"\\n✓ Climate Analysis Completed!\")\n",
    "    print(\"\\nStructured Output:\")\n",
    "    print(json.dumps(result.model_dump(), indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Practices and Patterns\n",
    "\n",
    "Let's explore some important patterns for production use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherMeasurement(BaseModel):\n",
    "    measurement_id: str\n",
    "    temperature: float\n",
    "    unit: str\n",
    "    timestamp: datetime\n",
    "    \n",
    "    @validator('temperature')\n",
    "    def temperature_must_be_realistic(cls, v):\n",
    "        if v < -150 or v > 150:\n",
    "            raise ValueError('Temperature must be between -150 and 150 degrees')\n",
    "        return v\n",
    "    \n",
    "    @validator('unit')\n",
    "    def unit_must_be_valid(cls, v):\n",
    "        valid_units = {'F', 'C', 'K'}\n",
    "        if v.upper() not in valid_units:\n",
    "            raise ValueError(f'Unit must be one of {valid_units}')\n",
    "        return v.upper()\n",
    "\n",
    "# Test valid measurement\n",
    "measurement = WeatherMeasurement(\n",
    "    measurement_id=\"TEMP123\",\n",
    "    temperature=72.5,\n",
    "    unit=\"f\",\n",
    "    timestamp=datetime.now()\n",
    ")\n",
    "print(f\"Valid measurement: {measurement.temperature}°{measurement.unit}\")\n",
    "\n",
    "# Test invalid temperature\n",
    "try:\n",
    "    invalid_measurement = WeatherMeasurement(\n",
    "        measurement_id=\"TEMP124\",\n",
    "        temperature=200.0,\n",
    "        unit=\"F\",\n",
    "        timestamp=datetime.now()\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(f\"\\nValidation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStationInfo(BaseModel):\n",
    "    station_name: str\n",
    "    contact_email: EmailStr\n",
    "    station_id: str = Field(pattern=r\"^WX\\d{6}$\")\n",
    "\n",
    "class StationRegistration(BaseStationInfo):\n",
    "    access_code: str = Field(min_length=8, max_length=128)\n",
    "    confirm_code: str\n",
    "    calibration_verified: bool = True\n",
    "    \n",
    "    @validator('confirm_code')\n",
    "    def codes_match(cls, v, values):\n",
    "        if 'access_code' in values and v != values['access_code']:\n",
    "            raise ValueError('Access codes do not match')\n",
    "        return v\n",
    "\n",
    "class StationProfile(BaseStationInfo):\n",
    "    location_description: Optional[str] = Field(default=None, max_length=500)\n",
    "    station_url: Optional[HttpUrl] = None\n",
    "    installed_at: datetime\n",
    "    last_reading: Optional[datetime] = None\n",
    "\n",
    "# Create instances\n",
    "registration = StationRegistration(\n",
    "    station_name=\"Downtown Weather Station\",\n",
    "    contact_email=\"admin@weather.gov\",\n",
    "    station_id=\"WX123456\",\n",
    "    access_code=\"SecureCode123\",\n",
    "    confirm_code=\"SecureCode123\"\n",
    ")\n",
    "\n",
    "profile = StationProfile(\n",
    "    station_name=\"Downtown Weather Station\",\n",
    "    contact_email=\"admin@weather.gov\",\n",
    "    station_id=\"WX123456\",\n",
    "    installed_at=datetime.now(),\n",
    "    location_description=\"Urban monitoring station\"\n",
    ")\n",
    "\n",
    "print(\"Registration:\", registration.station_name)\n",
    "print(\"Profile:\", profile.station_name, \"-\", profile.location_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safe Validation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def safe_validate(\n",
    "    data: Union[str, dict],\n",
    "    model: type[BaseModel]\n",
    ") -> tuple[BaseModel | None, dict]:\n",
    "    \"\"\"\n",
    "    Safely validate data with detailed error information.\n",
    "    \n",
    "    Returns:\n",
    "        (validated_model, error_info) where error_info is empty dict if successful\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(data, str):\n",
    "            validated = model.model_validate_json(data)\n",
    "        else:\n",
    "            validated = model.model_validate(data)\n",
    "        return validated, {}\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        return None, {\n",
    "            \"error_type\": \"json_decode\",\n",
    "            \"message\": str(e),\n",
    "            \"position\": e.pos\n",
    "        }\n",
    "        \n",
    "    except ValidationError as e:\n",
    "        return None, {\n",
    "            \"error_type\": \"validation\",\n",
    "            \"errors\": [\n",
    "                {\n",
    "                    \"field\": \".\".join(str(x) for x in err[\"loc\"]),\n",
    "                    \"message\": err[\"msg\"],\n",
    "                    \"type\": err[\"type\"]\n",
    "                }\n",
    "                for err in e.errors()\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Test the helper\n",
    "test_data = '{\"station_id\": \"Test\", \"location\": \"Chicago\", \"temperature\": \"very_hot\", \"conditions\": \"Sunny\"}'\n",
    "result, error_info = safe_validate(test_data, WeatherReport)\n",
    "\n",
    "if result:\n",
    "    print(\"✓ Validation successful\")\n",
    "else:\n",
    "    print(\"✗ Validation failed:\")\n",
    "    print(json.dumps(error_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Takeaways and Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Start with Clear Models**: Well-defined Pydantic models are the foundation of reliable weather data processing\n",
    "\n",
    "2. **Use Schema Over Examples**: Pass `model_json_schema()` to LLMs for better structured weather output\n",
    "\n",
    "3. **Implement Retry Logic**: LLMs don't always get it right the first time; build in error handling and retries\n",
    "\n",
    "4. **Validate Early and Often**: Catch data issues as early as possible in your weather pipeline\n",
    "\n",
    "5. **Leverage Type Safety**: Pydantic's type checking prevents many runtime errors in meteorological data\n",
    "\n",
    "6. **Document Your Models**: Use `Field(description=...)` to make weather models self-documenting\n",
    "\n",
    "7. **Test Thoroughly**: Write tests for both valid and invalid weather data scenarios\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Modern LLM APIs (like OpenAI) support passing Pydantic models directly for structured weather outputs\n",
    "- Explore instructor library for even more streamlined LLM + Pydantic weather workflows\n",
    "- Build production-ready validation pipelines for meteorological data with comprehensive error handling\n",
    "- Consider using Pydantic v2 for improved performance in weather data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Practice Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create a model for a weather observation report\n",
    "# Requirements:\n",
    "# - station_name: string\n",
    "# - observer_name: string\n",
    "# - temperature: float between -100 and 150\n",
    "# - observation_notes: string (min 50 chars)\n",
    "# - observation_date: date\n",
    "# - severe_weather: boolean\n",
    "# - weather_type: one of [\"clear\", \"cloudy\", \"rainy\", \"stormy\", \"snowy\"]\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create a prompt for the LLM to analyze a weather observation\n",
    "# and validate the response using your model\n",
    "\n",
    "sample_observation = \"\"\"Observed conditions at Central Park Weather Station today: Temperature reached 78°F with clear skies and light winds from the southwest. \n",
    "Visibility excellent at 10+ miles with no precipitation. Perfect conditions for outdoor activities. \n",
    "No severe weather warnings in effect for the metropolitan area.\"\"\"\n",
    "\n",
    "# Your code here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
