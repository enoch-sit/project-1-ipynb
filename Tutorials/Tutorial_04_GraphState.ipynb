{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Concepts: Threads, State, Persistence, and Streaming\n",
        "\n",
        "This comprehensive tutorial explains core LangGraph concepts through practical examples using AWS Bedrock and Tavily Search.\n",
        "\n",
        "## Analogy: Think of Your Phone's Messaging App\n",
        "\n",
        "- **THREAD** = One conversation with a friend (identified by contact name)\n",
        "- **STATE** = All the messages in that conversation + current context\n",
        "- **PERSISTENCE** = Your phone saves conversations even when you close the app\n",
        "- **STREAMING** = Messages appear word-by-word as someone types\n",
        "- **CHECKPOINT** = Like taking a screenshot of the conversation at any point\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. Creating tools for your agent\n",
        "2. Understanding and managing STATE\n",
        "3. Using THREADS for multiple conversations\n",
        "4. Adding PERSISTENCE to remember conversations\n",
        "5. STREAMING responses in real-time\n",
        "6. Human-in-the-loop approval workflows\n",
        "7. Modifying state and time travel through checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Installation and Setup\n",
        "\n",
        "Install all required packages for building LangGraph agents with AWS Bedrock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q langgraph langchain-aws langchain-core tavily-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Initial Configuration\n",
        "\n",
        "### Security Best Practices\n",
        "\n",
        "Store credentials in Google Colab secrets:\n",
        "1. Click the 🔑 key icon in the left sidebar\n",
        "2. Add these secrets:\n",
        "   - `awsid`: Your AWS Access Key ID\n",
        "   - `awssecret`: Your AWS Secret Access Key\n",
        "   - `tavily`: Your Tavily API key from https://tavily.com\n",
        "\n",
        "### About Tavily\n",
        "\n",
        "Tavily is the web access layer for AI agents, providing:\n",
        "- **Fast Search**: Optimized for AI agents with sub-second response times\n",
        "- **Relevant Results**: Purpose-built for LLMs and RAG applications\n",
        "- **Real-time Data**: Up-to-date information from across the web\n",
        "- **Easy Integration**: Simple API with Python, Node.js, and cURL support\n",
        "\n",
        "Tavily is trusted by 700k+ developers and integrates seamlessly with LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "from langchain_aws import ChatBedrock\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "# Configure AWS credentials\n",
        "AWS_ACCESS_KEY_ID = userdata.get('awsid')\n",
        "AWS_SECRET_ACCESS_KEY = userdata.get('awssecret')\n",
        "AWS_REGION = \"us-east-1\"\n",
        "\n",
        "# Configure Tavily API key\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('tavily')\n",
        "\n",
        "# Initialize Bedrock client\n",
        "bedrock_runtime = boto3.client(\n",
        "    service_name='bedrock-runtime',\n",
        "    region_name=AWS_REGION,\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
        ")\n",
        "\n",
        "# Set up the Bedrock model\n",
        "llm = ChatBedrock(\n",
        "    client=bedrock_runtime,\n",
        "    model_id=\"amazon.nova-lite-v1:0\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 4096\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"✓ AWS Bedrock client initialized\")\n",
        "print(\"✓ Tavily API key configured\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"READY TO START LEARNING!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Tools\n",
        "\n",
        "### What are Tools?\n",
        "\n",
        "Tools are functions your agent can call to get information or perform actions.\n",
        "Think of them like apps on your phone - the agent decides when to use them.\n",
        "\n",
        "We'll create two tools:\n",
        "1. **Tavily Search**: Search the web for real-time information\n",
        "2. **Travel Budget Calculator**: Calculate estimated travel costs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# Create Tavily search tool (max 2 results to keep context manageable)\n",
        "search_tool = TavilySearchResults(max_results=2)\n",
        "\n",
        "# Create a custom travel budget calculator tool\n",
        "@tool\n",
        "def get_travel_budget(destination: str, days: int) -> str:\n",
        "    \"\"\"Calculate estimated travel budget for a destination.\n",
        "    \n",
        "    Args:\n",
        "        destination: The city or country to visit\n",
        "        days: Number of days for the trip\n",
        "    \"\"\"\n",
        "    base_costs = {\n",
        "        \"paris\": 200,\n",
        "        \"tokyo\": 180,\n",
        "        \"bali\": 80,\n",
        "        \"new york\": 250,\n",
        "        \"london\": 220,\n",
        "        \"default\": 150\n",
        "    }\n",
        "    \n",
        "    cost_per_day = base_costs.get(destination.lower(), base_costs[\"default\"])\n",
        "    total = cost_per_day * days\n",
        "    \n",
        "    return f\"Estimated budget for {destination} for {days} days: ${total} (${cost_per_day}/day for accommodation + food + local transport)\"\n",
        "\n",
        "tools = [search_tool, get_travel_budget]\n",
        "\n",
        "print(f\"✓ Created {len(tools)} tools\")\n",
        "print(f\"  1. {tools[0].name}: {tools[0].description}\")\n",
        "print(f\"  2. {tools[1].name}: {tools[1].description}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Understanding STATE\n",
        "\n",
        "### What is STATE?\n",
        "\n",
        "STATE is like the agent's memory. It stores:\n",
        "- All messages in the conversation\n",
        "- Current context and information\n",
        "- What happened so far\n",
        "\n",
        "### Example\n",
        "\n",
        "If you ask \"Book a hotel in Paris\" then ask \"What's the weather?\",\n",
        "the STATE remembers you're talking about Paris!\n",
        "\n",
        "### The `Annotated` Type\n",
        "\n",
        "The `Annotated[list, add_messages]` part tells LangGraph:\n",
        "- `list`: Messages are stored in a list\n",
        "- `add_messages`: New messages get **ADDED** to the list (not replaced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our state\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"The agent's working memory.\"\"\"\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "print(\"✓ State defined: Our agent will remember all conversation messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create the Basic Agent (Without Persistence)\n",
        "\n",
        "### Agent Workflow\n",
        "\n",
        "Our agent follows this pattern:\n",
        "1. **Receive input** → Go to agent node\n",
        "2. **Agent decides**: Do I need tools, or can I answer directly?\n",
        "   - If tools needed → Go to tools node\n",
        "   - If no tools needed → END\n",
        "3. **Tools execute** → Return results to agent\n",
        "4. **Agent uses tool results** → Formulate final answer → END\n",
        "\n",
        "This is called a **ReAct loop** (Reasoning and Acting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def should_continue(state: AgentState):\n",
        "    \"\"\"Decide if we should call tools or finish.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    \n",
        "    # If the AI wants to use tools, continue to tools\n",
        "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    # Otherwise, we're done\n",
        "    return END\n",
        "\n",
        "def call_model(state: AgentState):\n",
        "    \"\"\"Call the AI model.\"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    response = llm.bind_tools(tools).invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Create the graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Define the flow\n",
        "workflow.add_edge(START, \"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# Compile WITHOUT persistence\n",
        "basic_agent = workflow.compile()\n",
        "\n",
        "print(\"✓ Basic agent created (NO memory between sessions)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Testing Without Persistence\n",
        "\n",
        "### The Problem with No Persistence\n",
        "\n",
        "Watch what happens when the agent has NO memory between calls.\n",
        "Each `invoke()` is completely independent - the agent forgets everything!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION 1: AGENT WITHOUT PERSISTENCE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# First conversation\n",
        "print(\"\\n👤 User: What's a good budget for 5 days in Tokyo?\\n\")\n",
        "response = basic_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What's a good budget for 5 days in Tokyo?\")]\n",
        "})\n",
        "print(f\"🤖 Agent: {response['messages'][-1].content}\")\n",
        "\n",
        "# Try to reference the previous conversation\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"👤 User: What about for 7 days?\\n\")\n",
        "response = basic_agent.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What about for 7 days?\")]\n",
        "})\n",
        "print(f\"🤖 Agent: {response['messages'][-1].content}\")\n",
        "\n",
        "print(\"\\n⚠️  PROBLEM: The agent is confused! It doesn't remember Tokyo!\")\n",
        "print(\"    This is because we didn't save the state between calls.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Adding Persistence (Checkpointing)\n",
        "\n",
        "### What is Persistence?\n",
        "\n",
        "**PERSISTENCE** = Saving the state so conversations can continue later\n",
        "\n",
        "**CHECKPOINT** = A snapshot of the state at a specific point in time\n",
        "\n",
        "Think of it like saving a video game - you can come back later and continue where you left off!\n",
        "\n",
        "### Types of Checkpointers\n",
        "\n",
        "- **MemorySaver**: Saves in RAM (lost when program ends)\n",
        "- **SqliteSaver**: Saves to database (persists between runs)\n",
        "\n",
        "We'll use MemorySaver for this tutorial since it's simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a checkpointer\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile WITH persistence\n",
        "agent_with_memory = workflow.compile(checkpointer=memory)\n",
        "\n",
        "print(\"✓ Agent with memory created!\")\n",
        "print(\"  Now the agent will remember conversations within each thread.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Understanding Threads\n",
        "\n",
        "### What is a Thread?\n",
        "\n",
        "**THREAD** = A unique conversation identified by an ID\n",
        "\n",
        "### Analogy: WhatsApp Chats\n",
        "\n",
        "Imagine your WhatsApp app:\n",
        "- Thread `'alice'` = Your chat with Alice\n",
        "- Thread `'bob'` = Your chat with Bob\n",
        "- Thread `'family'` = Your family group chat\n",
        "\n",
        "### Key Points\n",
        "\n",
        "- Each thread has its own STATE (conversation history)\n",
        "- You can have multiple threads running at the same time\n",
        "- Threads are isolated - they don't interfere with each other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Using Threads - Practical Example\n",
        "\n",
        "Let's simulate helping TWO different users at the same time.\n",
        "Each user gets their own thread, maintaining separate conversation contexts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION 2: USING THREADS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# User 1's conversation (Thread: user_sarah)\n",
        "print(\"\\n👤 USER 1 (Sarah) - Thread ID: 'user_sarah'\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "config_sarah = {\"configurable\": {\"thread_id\": \"user_sarah\"}}\n",
        "\n",
        "response = agent_with_memory.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"I want to plan a trip to Paris for 3 days\")]\n",
        "}, config=config_sarah)\n",
        "\n",
        "print(f\"🤖 Response: {response['messages'][-1].content}\\n\")\n",
        "\n",
        "# User 2's conversation (Thread: user_john)\n",
        "print(\"👤 USER 2 (John) - Thread ID: 'user_john'\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "config_john = {\"configurable\": {\"thread_id\": \"user_john\"}}\n",
        "\n",
        "response = agent_with_memory.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"I'm thinking of visiting Tokyo for a week\")]\n",
        "}, config=config_john)\n",
        "\n",
        "print(f\"🤖 Response: {response['messages'][-1].content}\\n\")\n",
        "\n",
        "# Continue Sarah's conversation\n",
        "print(\"👤 USER 1 (Sarah) continues - SAME thread 'user_sarah'\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "response = agent_with_memory.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What about for 5 days instead?\")]\n",
        "}, config=config_sarah)\n",
        "\n",
        "print(f\"🤖 Response: {response['messages'][-1].content}\")\n",
        "print(\"✓ The agent remembered we were talking about PARIS!\\n\")\n",
        "\n",
        "# Continue John's conversation\n",
        "print(\"👤 USER 2 (John) continues - SAME thread 'user_john'\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "response = agent_with_memory.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What's the weather like there now?\")]\n",
        "}, config=config_john)\n",
        "\n",
        "print(f\"🤖 Response: {response['messages'][-1].content}\")\n",
        "print(\"✓ The agent remembered we were talking about TOKYO!\\n\")\n",
        "\n",
        "print(\"🎯 KEY INSIGHT: Each thread maintains its OWN conversation!\")\n",
        "print(\"   Sarah's thread knows about Paris, John's thread knows about Tokyo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Inspecting State\n",
        "\n",
        "You can look inside any thread's state to see:\n",
        "- All messages in the conversation\n",
        "- What the next step will be\n",
        "- The checkpoint configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Sarah's state\n",
        "sarah_state = agent_with_memory.get_state(config_sarah)\n",
        "\n",
        "print(\"👤 Sarah's conversation STATE:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Number of messages: {len(sarah_state.values['messages'])}\")\n",
        "print(f\"Next step: {sarah_state.next}\")\n",
        "print(\"\\nMessages in order:\")\n",
        "\n",
        "for i, msg in enumerate(sarah_state.values['messages'], 1):\n",
        "    msg_type = type(msg).__name__\n",
        "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
        "    # Truncate long messages\n",
        "    if len(str(content)) > 100:\n",
        "        content = str(content)[:100] + \"...\"\n",
        "    print(f\"  {i}. {msg_type}: {content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Streaming Responses\n",
        "\n",
        "### What is Streaming?\n",
        "\n",
        "**STREAMING** = Getting responses in real-time, not waiting for completion\n",
        "\n",
        "Like seeing '...' when someone is typing on WhatsApp!\n",
        "\n",
        "### Two Types of Streaming\n",
        "\n",
        "1. **Stream EVENTS**: See each step (tool call, tool result, final answer)\n",
        "2. **Stream TOKENS**: See words generated one-by-one (not covered here)\n",
        "\n",
        "We'll demonstrate event streaming to see the agent's reasoning process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION 3: STREAMING EVENTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "config_streaming = {\"configurable\": {\"thread_id\": \"user_streaming_demo\"}}\n",
        "\n",
        "print(\"\\n👤 User asks: 'What are the best attractions in Bali?'\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n🔄 STREAMING EVENTS (step-by-step):\\n\")\n",
        "\n",
        "for event in agent_with_memory.stream({\n",
        "    \"messages\": [HumanMessage(content=\"What are the best attractions in Bali?\")]\n",
        "}, config=config_streaming):\n",
        "    \n",
        "    for node_name, node_output in event.items():\n",
        "        print(f\"📍 Node: {node_name}\")\n",
        "        \n",
        "        if \"messages\" in node_output:\n",
        "            message = node_output[\"messages\"][-1]\n",
        "            \n",
        "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "                print(f\"   🔧 AI wants to use tool: {message.tool_calls[0]['name']}\")\n",
        "                print(f\"   📝 Arguments: {message.tool_calls[0]['args']}\")\n",
        "            elif hasattr(message, 'content') and message.content:\n",
        "                print(f\"   💬 Response: {message.content[:100]}...\")\n",
        "            elif hasattr(message, 'name'):\n",
        "                print(f\"   🛠️  Tool '{message.name}' executed\")\n",
        "        \n",
        "        print()\n",
        "\n",
        "print(\"✓ Streaming complete! You saw each step as it happened.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Human-in-the-Loop (Interrupting for Approval)\n",
        "\n",
        "### What is Human-in-the-Loop?\n",
        "\n",
        "**HUMAN-IN-THE-LOOP** = Pausing execution to get human approval before taking actions\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- Approve before booking a flight\n",
        "- Approve before making a purchase  \n",
        "- Approve before sending an email\n",
        "- Review tool calls before execution\n",
        "\n",
        "### How It Works\n",
        "\n",
        "We use `interrupt_before=[\"tools\"]` to pause execution BEFORE the agent calls tools.\n",
        "This lets us review what the agent wants to do and approve or modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an agent that interrupts before using tools\n",
        "agent_with_approval = workflow.compile(\n",
        "    checkpointer=memory,\n",
        "    interrupt_before=[\"tools\"]  # ⚠️ PAUSE before using tools!\n",
        ")\n",
        "\n",
        "print(\"✓ Agent created with interrupt BEFORE tools\")\n",
        "print(\"\\nLet's try it...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "config_approval = {\"configurable\": {\"thread_id\": \"user_approval_demo\"}}\n",
        "\n",
        "print(\"\\n👤 User: 'Search for luxury hotels in Bali'\\n\")\n",
        "\n",
        "# This will stop BEFORE calling the search tool\n",
        "response = agent_with_approval.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Search for luxury hotels in Bali\")]\n",
        "}, config=config_approval)\n",
        "\n",
        "print(\"🤖 Agent wants to take action but is PAUSED!\\n\")\n",
        "\n",
        "# Check the state\n",
        "current_state = agent_with_approval.get_state(config_approval)\n",
        "print(f\"📊 Current state:\")\n",
        "print(f\"   Next node: {current_state.next}\")\n",
        "print(f\"   Status: Waiting for approval to proceed to '{current_state.next[0]}'\\n\")\n",
        "\n",
        "# Look at what the agent wants to do\n",
        "last_message = current_state.values['messages'][-1]\n",
        "if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "    tool_call = last_message.tool_calls[0]\n",
        "    print(f\"🔧 Agent wants to call: {tool_call['name']}\")\n",
        "    print(f\"📝 With arguments: {json.dumps(tool_call['args'], indent=2)}\\n\")\n",
        "\n",
        "# Simulate human approval\n",
        "print(\"👨‍💼 Human reviews and APPROVES\\n\")\n",
        "print(\"▶️  Resuming execution...\\n\")\n",
        "\n",
        "# Continue execution by passing None (no new input, just continue)\n",
        "for event in agent_with_approval.stream(None, config=config_approval):\n",
        "    for node_name, node_output in event.items():\n",
        "        if node_name == \"tools\":\n",
        "            print(f\"🛠️  Tool executed!\")\n",
        "        elif node_name == \"agent\" and \"messages\" in node_output:\n",
        "            msg = node_output[\"messages\"][-1]\n",
        "            if hasattr(msg, 'content') and msg.content:\n",
        "                print(f\"💬 Final response: {msg.content[:150]}...\")\n",
        "\n",
        "print(\"\\n✓ Execution completed after human approval!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Modifying State (Editing the Past)\n",
        "\n",
        "### Why Modify State?\n",
        "\n",
        "You can MODIFY the state to:\n",
        "- Correct mistakes in the conversation\n",
        "- Change what the agent is about to do\n",
        "- Mock tool responses for testing\n",
        "- Override agent decisions\n",
        "\n",
        "### Use Case\n",
        "\n",
        "The agent wants to search for hotels in London, but you want Paris instead.\n",
        "We can modify the tool call arguments before execution!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_modify = {\"configurable\": {\"thread_id\": \"user_modify_demo\"}}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION 4: MODIFYING STATE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n👤 User: 'What's a good budget for 5 days in London?'\\n\")\n",
        "\n",
        "# Pause before tools\n",
        "response = agent_with_approval.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What's a good budget for 5 days in London?\")]\n",
        "}, config=config_modify)\n",
        "\n",
        "# Get the current state\n",
        "current_state = agent_with_approval.get_state(config_modify)\n",
        "last_message = current_state.values['messages'][-1]\n",
        "\n",
        "print(\"🤖 Agent wants to call tool:\")\n",
        "if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "    print(f\"   Tool: {last_message.tool_calls[0]['name']}\")\n",
        "    print(f\"   Args: {last_message.tool_calls[0]['args']}\\n\")\n",
        "\n",
        "print(\"👨‍💼 Human: 'Wait! Change it to Paris instead!'\\n\")\n",
        "\n",
        "# Modify the tool call\n",
        "if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "    tool_call_id = last_message.tool_calls[0]['id']\n",
        "    \n",
        "    modified_message = AIMessage(\n",
        "        content=\"\",\n",
        "        tool_calls=[{\n",
        "            'name': 'get_travel_budget',\n",
        "            'args': {'destination': 'Paris', 'days': 5},  # Changed!\n",
        "            'id': tool_call_id\n",
        "        }]\n",
        "    )\n",
        "    \n",
        "    # Update the state\n",
        "    agent_with_approval.update_state(\n",
        "        config_modify,\n",
        "        {\"messages\": [modified_message]}\n",
        "    )\n",
        "    \n",
        "    print(\"✓ State modified! Changed destination from London to Paris\\n\")\n",
        "\n",
        "# Check the new state\n",
        "new_state = agent_with_approval.get_state(config_modify)\n",
        "updated_message = new_state.values['messages'][-1]\n",
        "print(f\"🔄 Updated tool call:\")\n",
        "if hasattr(updated_message, 'tool_calls'):\n",
        "    print(f\"   Tool: {updated_message.tool_calls[0]['name']}\")\n",
        "    print(f\"   Args: {updated_message.tool_calls[0]['args']}\\n\")\n",
        "\n",
        "# Continue execution\n",
        "print(\"▶️  Continuing with modified state...\\n\")\n",
        "response = agent_with_approval.invoke(None, config=config_modify)\n",
        "print(f\"🤖 Final answer: {response['messages'][-1].content[:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Time Travel (Accessing Checkpoint History)\n",
        "\n",
        "### What is Time Travel?\n",
        "\n",
        "**CHECKPOINTS** save a snapshot after EACH step in the workflow.\n",
        "\n",
        "You can go back to ANY previous checkpoint and continue from there!\n",
        "\n",
        "### Analogy\n",
        "\n",
        "Like Git commits - you can checkout any previous state and continue development from that point.\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- Debug what went wrong at a specific step\n",
        "- Test alternative conversation paths\n",
        "- Recover from mistakes\n",
        "- Analyze agent decision-making"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_history = {\"configurable\": {\"thread_id\": \"user_history_demo\"}}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"DEMONSTRATION 5: TIME TRAVEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nLet's have a conversation with multiple turns...\\n\")\n",
        "\n",
        "messages_to_send = [\n",
        "    \"What's the budget for 3 days in Tokyo?\",\n",
        "    \"Now check Paris for 4 days\",\n",
        "    \"What about Bali for a week?\"\n",
        "]\n",
        "\n",
        "for user_msg in messages_to_send:\n",
        "    print(f\"👤 {user_msg}\")\n",
        "    response = agent_with_memory.invoke({\n",
        "        \"messages\": [HumanMessage(content=user_msg)]\n",
        "    }, config=config_history)\n",
        "    print(f\"🤖 {response['messages'][-1].content[:100]}...\\n\")\n",
        "\n",
        "# Now let's look at the history\n",
        "print(\"=\"*70)\n",
        "print(\"📜 VIEWING CHECKPOINT HISTORY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "history = list(agent_with_memory.get_state_history(config_history))\n",
        "\n",
        "print(f\"\\nTotal checkpoints saved: {len(history)}\\n\")\n",
        "print(\"Checkpoints (most recent first):\")\n",
        "\n",
        "for i, state in enumerate(history[:5]):  # Show first 5\n",
        "    print(f\"\\n{i+1}. Checkpoint ID: {state.config['configurable']['checkpoint_id'][:8]}...\")\n",
        "    print(f\"   Messages in state: {len(state.values['messages'])}\")\n",
        "    print(f\"   Next step: {state.next}\")\n",
        "    if state.values['messages']:\n",
        "        last_msg = state.values['messages'][-1]\n",
        "        msg_type = type(last_msg).__name__\n",
        "        print(f\"   Last message type: {msg_type}\")\n",
        "\n",
        "# Let's go back to an earlier checkpoint\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"⏪ TIME TRAVEL: Going back to checkpoint 3\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if len(history) >= 3:\n",
        "    old_checkpoint = history[2]  # Third most recent\n",
        "    \n",
        "    print(f\"\\nGoing back to checkpoint with {len(old_checkpoint.values['messages'])} messages\")\n",
        "    print(f\"We'll continue the conversation from there...\\n\")\n",
        "    \n",
        "    print(\"👤 (From the past) Now what about New York for 2 days?\")\n",
        "    \n",
        "    response = agent_with_memory.invoke({\n",
        "        \"messages\": [HumanMessage(content=\"Now what about New York for 2 days?\")]\n",
        "    }, config=old_checkpoint.config)  # Use the old checkpoint's config!\n",
        "    \n",
        "    print(f\"\\n🤖 {response['messages'][-1].content}\")\n",
        "    print(\"\\n✓ We successfully continued from an earlier point in time!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Key Concepts\n",
        "\n",
        "### 1. STATE\n",
        "- The agent's memory at any point in time\n",
        "- Contains conversation history and context\n",
        "- Like RAM in a computer\n",
        "\n",
        "### 2. THREAD\n",
        "- A unique conversation identified by an ID\n",
        "- Each thread has its own STATE\n",
        "- Like separate chat conversations with different people\n",
        "\n",
        "### 3. PERSISTENCE / CHECKPOINTING\n",
        "- Saving state snapshots so you can come back later\n",
        "- Checkpoint = snapshot after each step\n",
        "- Like saving a video game\n",
        "\n",
        "### 4. STREAMING\n",
        "- Getting responses in real-time\n",
        "- Two types: events (steps) and tokens (words)\n",
        "- Like seeing typing indicators\n",
        "\n",
        "### 5. HUMAN-IN-THE-LOOP\n",
        "- Pausing execution for human approval\n",
        "- `interrupt_before` = pause before certain nodes\n",
        "- Use for critical actions that need approval\n",
        "\n",
        "### 6. STATE MODIFICATION\n",
        "- You can edit the state at any point\n",
        "- Change what the agent is about to do\n",
        "- Correct mistakes or provide mock data\n",
        "\n",
        "### 7. TIME TRAVEL\n",
        "- Access any previous checkpoint\n",
        "- Continue from that point\n",
        "- Like Git checkout\n",
        "\n",
        "## Practical Uses\n",
        "\n",
        "✓ Customer support chatbots (each customer = 1 thread)\n",
        "\n",
        "✓ Multi-user applications (each user = 1 thread)\n",
        "\n",
        "✓ Complex workflows requiring approval\n",
        "\n",
        "✓ Debugging and testing (time travel, mocking)\n",
        "\n",
        "✓ Long-running tasks that can resume later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practice Exercises\n",
        "\n",
        "Try these exercises to solidify your understanding:\n",
        "\n",
        "### Exercise 1: Create and Inspect a Thread\n",
        "Create a new thread with `thread_id=\"practice1\"`. Ask about travel to 3 different cities, then inspect the state to see all messages.\n",
        "\n",
        "### Exercise 2: Multiple Simultaneous Threads\n",
        "Create TWO threads running simultaneously. Have different conversations in each and verify they don't interfere with each other.\n",
        "\n",
        "### Exercise 3: Human-in-the-Loop\n",
        "Use `interrupt_before` to pause before tool execution. Modify the tool arguments before continuing.\n",
        "\n",
        "### Exercise 4: Time Travel\n",
        "Create a conversation with 5+ turns. Go back to the 3rd checkpoint and continue from there with a different question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 1: Starter Code\n",
        "my_config = {\"configurable\": {\"thread_id\": \"practice1\"}}\n",
        "\n",
        "# Your code here:\n",
        "# 1. Ask about 3 different cities\n",
        "# 2. Inspect the state\n",
        "\n",
        "# Example:\n",
        "# response = agent_with_memory.invoke({\n",
        "#     \"messages\": [HumanMessage(content=\"Your question here\")]\n",
        "# }, config=my_config)\n",
        "\n",
        "# state = agent_with_memory.get_state(my_config)\n",
        "# print(f\"Messages: {len(state.values['messages'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Congratulations! 🎉\n",
        "\n",
        "You now understand:\n",
        "\n",
        "✓ How threads keep conversations separate\n",
        "\n",
        "✓ How state stores information\n",
        "\n",
        "✓ How persistence saves state\n",
        "\n",
        "✓ How streaming gives real-time feedback\n",
        "\n",
        "✓ How human-in-the-loop adds control\n",
        "\n",
        "✓ How to modify state and time travel\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Explore the [LangGraph documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- Try building your own agent with custom tools\n",
        "- Experiment with different checkpointer types (SqliteSaver for persistence)\n",
        "- Learn about streaming tokens for character-by-character output\n",
        "\n",
        "Happy coding! 🚀"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}